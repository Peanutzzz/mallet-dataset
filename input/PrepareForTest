abstract time base test run with power mock runner class prepare for test time util class public abstract class abstract time base test private long current millis power mockito mock static time util class power mockito when time util current time milli then return current millis protect final void use actual time power mockito when time util current time milli then call real method protect final void set current milli long cur current millis cur power mockito when time util current time milli then return current millis protect final void sleep int t current millis t power mockito when time util current time milli then return current millis protect final void sleep second int time sec sleep time sec 
abstract time base test run with power mock runner class prepare for test time util class public abstract class abstract time base test private long current millis power mockito mock static time util class power mockito when time util current time milli then return current millis protect final void use actual time power mockito when time util current time milli then call real method protect final void set current milli long cur current millis cur power mockito when time util current time milli then return current millis protect final void sleep int t current millis t power mockito when time util current time milli then return current millis protect final void sleep second int time sec sleep time sec 
kafka010 fetcher test run with power mock runner class prepare for test kafka consumer thread class public class kafka010 fetcher test test public void test commit do not block throw exception test datum final kafka topic partition test partition new kafka topic partition test final map kafka topic partition long test commit datum new hash map test commit datum put test partition 11 l to synchronize when the consumer be in its blocking method final one shot latch sync new one shot latch the mock consumer with block poll call final multi shot latch blocker latch new multi shot latch kafka consumer mock consumer mock kafka consumer class when mock consumer poll any long then answer new answer consumer record override public consumer record answer invocation on mock invocation throw interrupted exception sync trigger blocker latch await return consumer record empty do answer new answer void override public void answer invocation on mock invocation blocker latch trigger return null when mock consumer wakeup make sure the fetcher create the mock consumer when new kafka consumer class with any argument then return mock consumer create the test fetcher suppress warning unchecked source context string source context mock source context class map kafka topic partition long partition with initial offset collection singleton map new kafka topic partition test kafka topic partition state sentinel group offset kafka deserialization schema string schema new kafka deserialization schema wrapper new simple string schema final kafka010 fetcher string fetcher new kafka010 fetcher source context partition with initial offset null watermark strategy new test processing time service get class get class loader taskname with subtask schema new property 0 l new unregistered metric group new unregistered metric group false null run the fetcher final atomic reference throwable error new atomic reference final thread fetcher runner new thread fetcher runner override public void run try fetcher run fetch loop catch throwable t error set t fetcher runner start wait until the fetcher have reach the method of interest sync await trigger the offset commit final atomic reference throwable commit error new atomic reference final thread committer new thread committer runner override public void run try fetcher commit internal offset to kafka test commit datum mock kafka commit callback class catch throwable t commit error set t committer start ensure that the committer finish in time committer join assert false the committer do not finish in time committer be alive test do wait till the fetcher be do for a clean shutdown fetcher cancel fetcher runner join check that there be no error in the fetcher final throwable fetcher error error get if fetcher error null fetcher error instanceof handover close exception throw new exception exception in the fetcher fetcher error final throwable committer error commit error get if committer error null throw new exception exception in the committer committer error test public void ensure offset get commit throw exception test datum final kafka topic partition test partition1 new kafka topic partition test final kafka topic partition test partition2 new kafka topic partition another final map kafka topic partition long test commit data1 new hash map test commit data1 put test partition1 11 l test commit data1 put test partition2 18 l final map kafka topic partition long test commit data2 new hash map test commit data2 put test partition1 19 l test commit data2 put test partition2 28 l final blocking queue map topic partition offset and metadata commit store new link block queue the mock consumer with poll wakeup and commit a sync call final multi shot latch blocker latch new multi shot latch kafka consumer mock consumer mock kafka consumer class when mock consumer poll any long then answer new answer consumer record override public consumer record answer invocation on mock invocation throw interrupted exception blocker latch await return consumer record empty do answer new answer void override public void answer invocation on mock invocation blocker latch trigger return null when mock consumer wakeup do answer new answer void override public void answer invocation on mock invocation suppress warning unchecked map topic partition offset and metadata offset map topic partition offset and metadata invocation get argument offset commit callback callback offset commit callback invocation get argument commit store add offset callback on complete offset null return null when mock consumer commit async mockito map topic partition offset and metadata any any offset commit callback class make sure the fetcher create the mock consumer when new kafka consumer class with any argument then return mock consumer create the test fetcher suppress warning unchecked source context string source context mock source context class map kafka topic partition long partition with initial offset collection singleton map new kafka topic partition test kafka topic partition state sentinel group offset kafka deserialization schema string schema new kafka deserialization schema wrapper new simple string schema final kafka010 fetcher string fetcher new kafka010 fetcher source context partition with initial offset null watermark strategy new test processing time service get class get class loader taskname with subtask schema new property 0 l new unregistered metric group new unregistered metric group false null run the fetcher final atomic reference throwable error new atomic reference final thread fetcher runner new thread fetcher runner override public void run try fetcher run fetch loop catch throwable t error set t fetcher runner start trigger the first offset commit fetcher commit internal offset to kafka test commit data1 mock kafka commit callback class map topic partition offset and metadata result1 commit store take for entry topic partition offset and metadata entry result1 entry set topic partition partition entry get key if partition topic equal test assert equal partition partition assert equal 12 l entry get value offset else if partition topic equal another assert equal partition partition assert equal 18 l entry get value offset trigger the second offset commit fetcher commit internal offset to kafka test commit data2 mock kafka commit callback class map topic partition offset and metadata result2 commit store take for entry topic partition offset and metadata entry result2 entry set topic partition partition entry get key if partition topic equal test assert equal partition partition assert equal 20 l entry get value offset else if partition topic equal another assert equal partition partition assert equal 28 l entry get value offset test do wait till the fetcher be do for a clean shutdown fetcher cancel fetcher runner join check that there be no error in the fetcher final throwable catch error error get if catch error null catch error instanceof handover close exception throw new exception exception in the fetcher catch error test public void test cancellation when emit block throw exception some test datum final string topic test topic final int partition final byte payload new byte final list consumer record byte byte record array as list new consumer record topic partition payload payload new consumer record topic partition payload payload new consumer record topic partition payload payload final map topic partition list consumer record byte byte datum new hash map datum put new topic partition topic partition record final consumer record byte byte consumer record new consumer record datum the test consumer final kafka consumer mock consumer mock kafka consumer class when mock consumer poll any long then answer new answer consumer record override public consumer record answer invocation on mock invocation return consumer record when new kafka consumer class with any argument then return mock consumer build a fetcher block source context string source context new blocking source context map kafka topic partition long partition with initial offset collection singleton map new kafka topic partition topic partition kafka topic partition state sentinel group offset kafka deserialization schema string schema new kafka deserialization schema wrapper new simple string schema final kafka010 fetcher string fetcher new kafka010 fetcher source context partition with initial offset null watermark strategy new test processing time service watermark interval this get class get class loader task name schema new property 0 l new unregistered metric group new unregistered metric group false null run the fetcher final atomic reference throwable error new atomic reference final thread fetcher runner new thread fetcher runner override public void run try fetcher run fetch loop catch throwable t error set t fetcher runner start wait until the thread start to emit record to the source context source context wait till have blocker now we try to cancel the fetcher include the interruption usually do on the task thread once it have finish there must be no more thread block on the source context fetcher cancel fetcher runner interrupt fetcher runner join assert false fetcher thread do not properly finish source context be still block test utility private static final class block source context t implement source context t private final reentrant lock lock new reentrant lock private final one shot latch in block new one shot latch override public void collect t element block override public void collect with timestamp t element long timestamp block override public void emit watermark watermark mark block override public void mark as temporarily idle throw new unsupported operation exception override public object get checkpoint lock return new object override public void close void wait till have blocker throw interrupted exception in block await boolean be still block return lock be lock suppress warning infinite loop statement synchronization on local variable or method parameter private void block lock lock try in block trigger put this thread to sleep indefinitely final object o new object while true synchronize o o wait catch interrupted exception e exit cleanly simply reset the interruption flag thread current thread interrupt finally lock unlock 
kafka consumer thread test run with power mock runner class prepare for test handover class public class kafka consumer thread test test timeout public void test close without assign partition throw exception no initial assignment final consumer byte byte mock consumer create mock consumer new link hash map topic partition long collection topic partition long empty map false null null setup latch so the test wait until test thread be block on get batch blocking method final multi shot latch get batch block invoke new multi shot latch final closable blocking queue kafka topic partition state object topic partition unassigned partition queue new closable blocking queue kafka topic partition state object topic partition override public list kafka topic partition state object topic partition get batch blocking throw interrupted exception get batch block invoke trigger return super get batch block final test kafka consumer thread test thread new test kafka consumer thread mock consumer unassigned partition queue new handover test thread start get batch block invoke await test thread shutdown test thread join test reassignment work correctly in the case when the consumer initially have no assignment new unassigned partition already have define offset p set a timeout because the test will not finish if there be logic error with the reassignment flow suppress warning unchecked test timeout public void test reassign partition with define offset when no initial assignment throw exception final string test topic test topic new partition with define offset kafka topic partition state object topic partition new partition1 new kafka topic partition state new kafka topic partition test topic new topic partition test topic new partition1 set offset 23 l kafka topic partition state object topic partition new partition2 new kafka topic partition state new kafka topic partition test topic new topic partition test topic new partition2 set offset 31 l final list kafka topic partition state object topic partition new partition new array list new partition add new partition1 new partition add new partition2 setup mock kafka consumer no initial assignment final map topic partition long mock consumer assignment and position new link hash map final consumer byte byte mock consumer create mock consumer mock consumer assignment and position collection topic partition long empty map false null null setup new partition to be poll from the unassigned partition queue final closable blocking queue kafka topic partition state object topic partition unassigned partition queue new closable blocking queue for kafka topic partition state object topic partition new partition new partition unassigned partition queue add new partition start test final test kafka consumer thread test thread new test kafka consumer thread mock consumer unassigned partition queue new handover test thread start test thread start partition reassignment test thread wait partition reassignment complete verify that the consumer call assign with all new partition and that position be correctly advanced assert equal new partition size mock consumer assignment and position size for kafka topic partition state object topic partition new partition new partition assert true mock consumer assignment and position contain key new partition get kafka partition handle should be seek to offset in state because offset in state represent the last process record assert equal new partition get offset mock consumer assignment and position get new partition get kafka partition handle long value assert equal unassigned partition queue size test reassignment work correctly in the case when the consumer initially have no assignment new unassigned partition have undefined offset e g earliest offset sentinel value p set a timeout because the test will not finish if there be logic error with the reassignment flow suppress warning unchecked test timeout public void test reassign partition without define offset when no initial assignment throw exception final string test topic test topic new partition with undefined offset kafka topic partition state object topic partition new partition1 new kafka topic partition state new kafka topic partition test topic new topic partition test topic new partition1 set offset kafka topic partition state sentinel earliest offset kafka topic partition state object topic partition new partition2 new kafka topic partition state new kafka topic partition test topic new topic partition test topic new partition2 set offset kafka topic partition state sentinel earliest offset final list kafka topic partition state object topic partition new partition new array list new partition add new partition1 new partition add new partition2 setup mock kafka consumer no initial assignment final map topic partition long mock consumer assignment and position new link hash map mock retrieve value that should replace the earliest offset sentinel final map topic partition long mock retrieve position new hash map mock retrieve position put new partition1 get kafka partition handle 23 l mock retrieve position put new partition2 get kafka partition handle 32 l final consumer byte byte mock consumer create mock consumer mock consumer assignment and position mock retrieve position false null null setup new partition to be poll from the unassigned partition queue final closable blocking queue kafka topic partition state object topic partition unassigned partition queue new closable blocking queue for kafka topic partition state object topic partition new partition new partition unassigned partition queue add new partition start test final test kafka consumer thread test thread new test kafka consumer thread mock consumer unassigned partition queue new handover test thread start test thread start partition reassignment test thread wait partition reassignment complete the sentinel offset state should have be replace with define value accord to the retrieve value assert equal mock retrieve position get new partition1 get kafka partition handle new partition1 get offset assert equal mock retrieve position get new partition2 get kafka partition handle new partition2 get offset verify that the consumer call assign with all new partition and that position be correctly advanced assert equal new partition size mock consumer assignment and position size for kafka topic partition state object topic partition new partition new partition assert true mock consumer assignment and position contain key new partition get kafka partition handle should be seek to offset in state because offset in state represent the last process record assert equal new partition get offset mock consumer assignment and position get new partition get kafka partition handle long value assert equal unassigned partition queue size test reassignment work correctly in the case when the consumer already have some assignment new unassigned partition already have define offset p set a timeout because the test will not finish if there be logic error with the reassignment flow suppress warning unchecked test timeout public void test reassign partition with define offset throw exception final string test topic test topic old partition kafka topic partition state object topic partition old partition1 new kafka topic partition state new kafka topic partition test topic new topic partition test topic old partition1 set offset 23 l kafka topic partition state object topic partition old partition2 new kafka topic partition state new kafka topic partition test topic new topic partition test topic old partition2 set offset 32 l list kafka topic partition state object topic partition old partition new array list old partition add old partition1 old partition add old partition2 new partition with define offset kafka topic partition state object topic partition new partition new kafka topic partition state new kafka topic partition test topic new topic partition test topic new partition set offset 29 l list kafka topic partition state object topic partition total partition new array list total partition add old partition1 total partition add old partition2 total partition add new partition setup mock kafka consumer have initial assignment final map topic partition long mock consumer assignment and position new hash map for kafka topic partition state object topic partition old partition old partition mock consumer assignment and position put old partition get kafka partition handle old partition get offset final consumer byte byte mock consumer create mock consumer mock consumer assignment and position collection topic partition long empty map false null null setup new partition to be poll from the unassigned partition queue final closable blocking queue kafka topic partition state object topic partition unassigned partition queue new closable blocking queue unassigned partition queue add new partition start test final test kafka consumer thread test thread new test kafka consumer thread mock consumer unassigned partition queue new handover test thread start test thread start partition reassignment test thread wait partition reassignment complete verify that the consumer call assign with all new partition and that position be correctly advanced assert equal total partition size mock consumer assignment and position size old partition should be re seek to they previous position for kafka topic partition state object topic partition partition total partition assert true mock consumer assignment and position contain key partition get kafka partition handle should be seek to offset in state because offset in state represent the last process record assert equal partition get offset mock consumer assignment and position get partition get kafka partition handle long value assert equal unassigned partition queue size test reassignment work correctly in the case when the consumer already have some assignment new unassigned partition have undefined offset e g earliest offset sentinel value p set a timeout because the test will not finish if there be logic error with the reassignment flow suppress warning unchecked test timeout public void test reassign partition without define offset throw exception final string test topic test topic old partition kafka topic partition state object topic partition old partition1 new kafka topic partition state new kafka topic partition test topic new topic partition test topic old partition1 set offset 23 l kafka topic partition state object topic partition old partition2 new kafka topic partition state new kafka topic partition test topic new topic partition test topic old partition2 set offset 32 l list kafka topic partition state object topic partition old partition new array list old partition add old partition1 old partition add old partition2 new partition with undefined offset kafka topic partition state object topic partition new partition new kafka topic partition state new kafka topic partition test topic new topic partition test topic new partition set offset kafka topic partition state sentinel earliest offset list kafka topic partition state object topic partition total partition new array list total partition add old partition1 total partition add old partition2 total partition add new partition setup mock kafka consumer have initial assignment final map topic partition long mock consumer assignment and position new hash map for kafka topic partition state object topic partition old partition old partition mock consumer assignment and position put old partition get kafka partition handle old partition get offset mock retrieve value that should replace the earliest offset sentinel final map topic partition long mock retrieve position new hash map mock retrieve position put new partition get kafka partition handle 30 l final consumer byte byte mock consumer create mock consumer mock consumer assignment and position mock retrieve position false null null setup new partition to be poll from the unassigned partition queue final closable blocking queue kafka topic partition state object topic partition unassigned partition queue new closable blocking queue unassigned partition queue add new partition start test final test kafka consumer thread test thread new test kafka consumer thread mock consumer unassigned partition queue new handover test thread start test thread start partition reassignment test thread wait partition reassignment complete the sentinel offset state should have be replace with define value accord to the retrieve position assert equal mock retrieve position get new partition get kafka partition handle new partition get offset verify that the consumer call assign with all new partition and that position be correctly advanced assert equal total partition size mock consumer assignment and position size old partition should be re seek to they previous position for kafka topic partition state object topic partition partition total partition assert true mock consumer assignment and position contain key partition get kafka partition handle should be seek to offset in state because offset in state represent the last process record assert equal partition get offset mock consumer assignment and position get partition get kafka partition handle long value assert equal unassigned partition queue size test reassignment work correctly in the case when the consumer already have some assignment new unassigned partition already have define offset the consumer be wake up prior to the reassignment p in this case reassignment should not have occur at all and the consumer retain the original assignment p set a timeout because the test will not finish if there be logic error with the reassignment flow suppress warning unchecked test timeout public void test reassign partition with define offset when early wakeup throw exception final string test topic test topic old partition kafka topic partition state object topic partition old partition1 new kafka topic partition state new kafka topic partition test topic new topic partition test topic old partition1 set offset 23 l kafka topic partition state object topic partition old partition2 new kafka topic partition state new kafka topic partition test topic new topic partition test topic old partition2 set offset 32 l list kafka topic partition state object topic partition old partition new array list old partition add old partition1 old partition add old partition2 new partition with define offset kafka topic partition state object topic partition new partition new kafka topic partition state new kafka topic partition test topic new topic partition test topic new partition set offset 29 l setup mock kafka consumer initial assignment final map topic partition long mock consumer assignment to position new link hash map for kafka topic partition state object topic partition old partition old partition mock consumer assignment to position put old partition get kafka partition handle old partition get offset final test consumer mock consumer create mock consumer mock consumer assignment to position collection topic partition long empty map true null null setup new partition to be poll from the unassigned partition queue final closable blocking queue kafka topic partition state object topic partition unassigned partition queue new closable blocking queue unassigned partition queue add new partition start test final test kafka consumer thread test thread new test kafka consumer thread mock consumer unassigned partition queue new handover test thread start pause just before the reassignment so we can inject the wakeup test thread wait partition reassignment invoke test thread set offset to commit new hash map topic partition offset and metadata mock kafka commit callback class assert equal mock consumer get num wakeup call test thread start partition reassignment test thread wait partition reassignment complete the consumer s assignment should have remain untouched assert equal old partition size mock consumer assignment to position size for kafka topic partition state object topic partition old partition old partition assert true mock consumer assignment to position contain key old partition get kafka partition handle assert equal old partition get offset mock consumer assignment to position get old partition get kafka partition handle long value the new partition should have be re add to the unassigned partition queue assert equal unassigned partition queue size test reassignment work correctly in the case when the consumer have no initial assignment new unassigned partition have undefined offset the consumer be wake up prior to the reassignment p in this case reassignment should not have occur at all and the consumer retain the original assignment p set a timeout because the test will not finish if there be logic error with the reassignment flow suppress warning unchecked test timeout public void test reassign partition define offset without initial assignment when early wakeup throw exception final string test topic test topic new partition with define offset kafka topic partition state object topic partition new partition1 new kafka topic partition state new kafka topic partition test topic new topic partition test topic new partition1 set offset kafka topic partition state sentinel earliest offset kafka topic partition state object topic partition new partition2 new kafka topic partition state new kafka topic partition test topic new topic partition test topic new partition2 set offset kafka topic partition state sentinel earliest offset list kafka topic partition state object topic partition new partition new array list new partition add new partition1 new partition add new partition2 setup mock kafka consumer no initial assignment final map topic partition long mock consumer assignment and position new link hash map mock retrieve value that should replace the earliest offset sentinel final map topic partition long mock retrieve position new hash map mock retrieve position put new partition1 get kafka partition handle 23 l mock retrieve position put new partition2 get kafka partition handle 32 l final test consumer mock consumer create mock consumer mock consumer assignment and position mock retrieve position true null null setup new partition to be poll from the unassigned partition queue final closable blocking queue kafka topic partition state object topic partition unassigned partition queue new closable blocking queue for kafka topic partition state object topic partition new partition new partition unassigned partition queue add new partition start test final test kafka consumer thread test thread new test kafka consumer thread mock consumer unassigned partition queue new handover test thread start pause just before the reassignment so we can inject the wakeup test thread wait partition reassignment invoke test thread set offset to commit new hash map topic partition offset and metadata mock kafka commit callback class make sure the consumer be actually wake up assert equal mock consumer get num wakeup call test thread start partition reassignment test thread wait partition reassignment complete the consumer s assignment should have remain untouched in this case empty assert equal mock consumer assignment and position size the new partition should have be re add to the unassigned partition queue assert equal unassigned partition queue size test reassignment work correctly in the case when the consumer have no initial assignment new unassigned partition have undefined offset the consumer be wake up during the reassignment p in this case reassignment should have complete and the consumer be restore the wakeup call after the reassignment p set a timeout because the test will not finish if there be logic error with the reassignment flow suppress warning unchecked test timeout public void test reassign partition define offset without initial assignment when wakeup midway throw exception final string test topic test topic new partition with define offset kafka topic partition state object topic partition new partition1 new kafka topic partition state new kafka topic partition test topic new topic partition test topic new partition1 set offset kafka topic partition state sentinel earliest offset kafka topic partition state object topic partition new partition2 new kafka topic partition state new kafka topic partition test topic new topic partition test topic new partition2 set offset kafka topic partition state sentinel earliest offset list kafka topic partition state object topic partition new partition new array list new partition add new partition1 new partition add new partition2 setup mock kafka consumer no initial assignment final map topic partition long mock consumer assignment and position new link hash map mock retrieve value that should replace the earliest offset sentinel final map topic partition long mock retrieve position new hash map mock retrieve position put new partition1 get kafka partition handle 23 l mock retrieve position put new partition2 get kafka partition handle 32 l these latch be use to pause midway the reassignment process final one shot latch mid assignment latch new one shot latch final one shot latch continue assigment latch new one shot latch final test consumer mock consumer create mock consumer mock consumer assignment and position mock retrieve position false mid assignment latch continue assigment latch setup new partition to be poll from the unassigned partition queue final closable blocking queue kafka topic partition state object topic partition unassigned partition queue new closable blocking queue for kafka topic partition state object topic partition new partition new partition unassigned partition queue add new partition start test final test kafka consumer thread test thread new test kafka consumer thread mock consumer unassigned partition queue new handover test thread start test thread start partition reassignment wait until the reassignment have start mid assignment latch await test thread set offset to commit new hash map topic partition offset and metadata mock kafka commit callback class the wakeup in the set offset to commit call should have be buffer and not call on the consumer assert equal mock consumer get num wakeup call continue assigment latch trigger test thread wait partition reassignment complete verify that the consumer call assign with all new partition and that position be correctly advanced assert equal new partition size mock consumer assignment and position size for kafka topic partition state object topic partition new partition new partition assert true mock consumer assignment and position contain key new partition get kafka partition handle should be seek to offset in state because offset in state represent the last process record assert equal new partition get offset mock consumer assignment and position get new partition get kafka partition handle long value after the reassignment the consumer should be restore the wakeup call assert equal mock consumer get num wakeup call assert equal unassigned partition queue size test timeout public void test ratelimiting throw exception final string test topic test topic ratelimit setup mock kafka consumer with test datum final int partition final byte payload new byte final list consumer record byte byte record array as list new consumer record test topic partition payload payload new consumer record test topic partition payload payload final map topic partition list consumer record byte byte datum new hash map datum put new topic partition test topic partition record final consumer record byte byte consumer record new consumer record datum sleep for one second in each consumer poll call to return byte second final kafka consumer byte byte mock consumer mock kafka consumer class power mockito when mock consumer poll any long then answer invocation on mock consumer record when new kafka consumer class with any argument then return mock consumer new partition with define offset kafka topic partition state object topic partition new partition1 new kafka topic partition state new kafka topic partition test topic new topic partition test topic new partition1 set offset kafka topic partition state sentinel earliest offset list kafka topic partition state object topic partition new partition new array list new partition add new partition1 final closable blocking queue kafka topic partition state object topic partition unassigned partition queue new closable blocking queue for kafka topic partition state object topic partition new partition new partition unassigned partition queue add new partition ratelimiting property stream runtime context mock runtime context mock streaming runtime context class when mock runtime context get number of parallel subtask then return property property new property mock handover and logger handover mock handover power mockito mock handover class do nothing when mock handover produce any logger mock logger mock logger class metric group metric group new unregistered metric group flink connector rate limiter rate limiter new guava flink connector rate limiter rate limiter set rate 1 l rate limiter open mock runtime context test kafka consumer thread kafka consumer thread test thread new test kafka consumer thread rate limit mock logger mock handover property unassigned partition queue test 30 l false metric group metric group mock consumer rate limiter test thread start wait for seconds to ensure atleast call to consumer poll test thread join assert not null test thread get rate limiter assert equal test thread get rate limiter get rate in a period of seconds no more than call to poll should be make the expect rate be byte second and we read byte in every consumer poll call the rate limiter should thus slow down the call by seconds when the rate take effect verify mock consumer time poll any long test thread shutdown a testable link kafka consumer thread that inject multiple latch exactly before and after partition reassignment so that test be eligible to setup various condition before the reassignment happen and inspect reassignment result after it be complete private static class test kafka consumer thread extend kafka consumer thread object private final consumer byte byte mock consumer private final multi shot latch pre reassignment latch new multi shot latch private final multi shot latch start reassignment latch new multi shot latch private final multi shot latch reassignment complete latch new multi shot latch private final multi shot latch post reassignment latch new multi shot latch public test kafka consumer thread consumer byte byte mock consumer closable blocking queue kafka topic partition state object topic partition unassigned partition queue handover handover super mock logger class handover new property unassigned partition queue test kafka consumer thread false new unregistered metric group new unregistered metric group null this mock consumer mock consumer public void wait partition reassignment invoke throw interrupted exception pre reassignment latch await public void start partition reassignment start reassignment latch trigger public void wait partition reassignment complete throw interrupted exception reassignment complete latch await public void end partition reassignment post reassignment latch trigger override consumer byte byte get consumer property kafka property return mock consumer override void reassign partition list kafka topic partition state object topic partition new partition throw exception trigger block call on wait partition reassignment invoke pre reassignment latch trigger wait for start partition reassignment to be call start reassignment latch await try super reassign partition new partition finally trigger block call on wait partition reassignment complete reassignment complete latch trigger wait for end partition reassignment to be call post reassignment latch await suppress warning unchecked private static test consumer create mock consumer final map topic partition long mock consumer assignment and position final map topic partition long mock retrieve position final boolean early wakeup final one shot latch mid assignment latch final one shot latch continue assignment latch return new test consumer mock consumer assignment and position mock retrieve position early wakeup mid assignment latch continue assignment latch private static class test consumer implement consumer byte byte private final map topic partition long mock consumer assignment and position private final map topic partition long mock retrieve position private final boolean early wakeup private final one shot latch mid assignment latch private final one shot latch continue assignment latch private int num wakeup call private test consumer map topic partition long mock consumer assignment and position map topic partition long mock retrieve position boolean early wakeup one shot latch mid assignment latch one shot latch continue assignment latch this mock consumer assignment and position mock consumer assignment and position this mock retrieve position mock retrieve position this early wakeup early wakeup this mid assignment latch mid assignment latch this continue assignment latch continue assignment latch override public set topic partition assignment if mid assignment latch null mid assignment latch trigger if continue assignment latch null try continue assignment latch await catch interrupted exception e thread current thread interrupt return mock consumer assignment and position key set override public set string subscription throw new unsupported operation exception override public void subscribe collection string collection override public void subscribe collection string collection consumer rebalance listener consumer rebalance listener override public void assign collection topic partition assign partition mock consumer assignment and position clear for topic partition assign assign partition mock consumer assignment and position put assign null override public void subscribe pattern pattern consumer rebalance listener consumer rebalance listener override public void unsubscribe override public consumer record byte byte poll long l return mock consumer record class override public void commit sync override public void commit sync map topic partition offset and metadata map override public void commit async override public void commit async offset commit callback offset commit callback override public void commit async map topic partition offset and metadata map offset commit callback offset commit callback override public void seek topic partition partition long position if mock consumer assignment and position contain key partition throw new runtime exception the current mock assignment do not contain partition partition else mock consumer assignment and position put partition position override public void seek to begin collection topic partition partition for topic partition partition partition if mock consumer assignment and position contain key partition throw new runtime exception the current mock assignment do not contain partition partition else long mock retrieve position mock retrieve position get partition if mock retrieve position null throw new runtime exception mock consumer need to retrieve a position but no value be provide in the mock value for retrieval else mock consumer assignment and position put partition mock retrieve position get partition override public void seek to end collection topic partition partition for topic partition partition partition if mock consumer assignment and position contain key partition throw new runtime exception the current mock assignment do not contain partition partition else long mock retrieve position mock retrieve position get partition if mock retrieve position null throw new runtime exception mock consumer need to retrieve a position but no value be provide in the mock value for retrieval else mock consumer assignment and position put partition mock retrieve position get partition override public long position topic partition topic partition if early wakeup return mock consumer assignment and position get topic partition else throw new wakeup exception override public offset and metadata commit topic partition topic partition throw new unsupported operation exception override public map metric name extend metric metric throw new unsupported operation exception override public list partition info partition for string s throw new unsupported operation exception override public map string list partition info list topic throw new unsupported operation exception override public set topic partition pause throw new unsupported operation exception override public void pause collection topic partition collection override public void resume collection topic partition collection override public map topic partition offset and timestamp offset for time map topic partition long map throw new unsupported operation exception override public map topic partition long beginning offset collection topic partition collection throw new unsupported operation exception override public map topic partition long end offset collection topic partition collection throw new unsupported operation exception override public void close override public void close long l time unit time unit override public void wakeup num wakeup call public int get num wakeup call return num wakeup call a testable kafka consumer thread to test the ratelimiting feature use user define property the mock consumer do not mock all the method mock in link test kafka consumer thread private static class test kafka consumer thread rate limit extend kafka consumer thread consumer byte byte mock consumer public test kafka consumer thread rate limit logger log handover handover property kafka property closable block queue kafka topic partition state object topic partition unassigned partition queue string thread name long poll timeout boolean use metric metric group consumer metric group metric group subtask metric group consumer byte byte mock consumer flink connector rate limiter rate limiter super log handover kafka property unassigned partition queue thread name poll timeout use metric consumer metric group subtask metric group rate limiter this mock consumer mock consumer override public consumer byte byte get consumer property property return mock consumer 
flink kinesis consumer test run with power mock runner class prepare for test flink kinesis consumer class kinesis config util class public class flink kinesis consumer test extend test logger test relate to state initialization test public void test use restore state for snapshot if fetcher not initialize throw exception property config test util get standard property list tuple2 stream shard metadata sequence number global union state new array list global union state add tuple2 of kinesis datum fetcher convert to stream shard metadata new stream shard handle fake stream new shard with shard id kinesis shard id generator generate from shard order new sequence number global union state add tuple2 of kinesis datum fetcher convert to stream shard metadata new stream shard handle fake stream new shard with shard id kinesis shard id generator generate from shard order new sequence number global union state add tuple2 of kinesis datum fetcher convert to stream shard metadata new stream shard handle fake stream new shard with shard id kinesis shard id generator generate from shard order new sequence number global union state add tuple2 of kinesis datum fetcher convert to stream shard metadata new stream shard handle fake stream new shard with shard id kinesis shard id generator generate from shard order new sequence number testing list state tuple2 stream shard metadata sequence number list state new testing list state for tuple2 stream shard metadata sequence number state global union state list state add state flink kinesis consumer string consumer new flink kinesis consumer fake stream new simple string schema config runtime context context mock runtime context class when context get index of this subtask then return when context get number of parallel subtask then return consumer set runtime context context operator state store operator state store mock operator state store class when operator state store get union list state matcher any list state descriptor class then return list state state initialization context initialization context mock state initialization context class when initialization context get operator state store then return operator state store when initialization context be restore then return true consumer initialize state initialization context only open not run consumer open new configuration arbitrary checkpoint id and timestamp consumer snapshot state new state snapshot context synchronous impl assert true list state be clear call the checkpointed list state should contain only the shard that it should subscribe to assert equal global union state size list state get list size assert true list state get list contain global union state get assert true list state get list contain global union state get test public void test list state change after snapshot state throw exception setup config initial state and expect state snapshot property config test util get standard property array list tuple2 stream shard metadata sequence number initial state new array list initial state add tuple2 of kinesis datum fetcher convert to stream shard metadata new stream shard handle fake stream1 new shard with shard id kinesis shard id generator generate from shard order new sequence number array list tuple2 stream shard metadata sequence number expect state snapshot new array list expect state snapshot add tuple2 of kinesis datum fetcher convert to stream shard metadata new stream shard handle fake stream1 new shard with shard id kinesis shard id generator generate from shard order new sequence number expect state snapshot add tuple2 of kinesis datum fetcher convert to stream shard metadata new stream shard handle fake stream1 new shard with shard id kinesis shard id generator generate from shard order new sequence number expect state snapshot add tuple2 of kinesis datum fetcher convert to stream shard metadata new stream shard handle fake stream1 new shard with shard id kinesis shard id generator generate from shard order new sequence number mock operator state backend and initial state for initialize state testing list state tuple2 stream shard metadata sequence number list state new testing list state for tuple2 stream shard metadata sequence number state initial state list state add state operator state store operator state store mock operator state store class when operator state store get union list state matcher any list state descriptor class then return list state state initialization context initialization context mock state initialization context class when initialization context get operator state store then return operator state store when initialization context be restore then return true mock a run fetcher and its state for snapshot hash map stream shard metadata sequence number state snapshot new hash map for tuple2 stream shard metadata sequence number tuple expect state snapshot state snapshot put tuple f0 tuple f1 kinesis datum fetcher mock fetcher mock kinesis datum fetcher class when mock fetcher snapshot state then return state snapshot create a consumer and test the snapshot state flink kinesis consumer string consumer new flink kinesis consumer fake stream new simple string schema config flink kinesis consumer mock consumer spy consumer runtime context context mock runtime context class when context get index of this subtask then return mock consumer set runtime context context mock consumer initialize state initialization context mock consumer open new configuration whitebox set internal state mock consumer fetcher mock fetcher mock consumer as run mock consumer snapshot state mock function snapshot context class assert equal true list state clear call assert equal list state get list size for tuple2 stream shard metadata sequence number state initial state for tuple2 stream shard metadata sequence number current state list state get list assert not equal state current state for tuple2 stream shard metadata sequence number state expect state snapshot boolean have one be same false for tuple2 stream shard metadata sequence number current state list state get list have one be same have one be same state equal current state assert equal true have one be same test relate to fetcher initialization test suppress warning unchecked public void test fetcher should not be restore from failure if not restore from checkpoint throw exception kinesis datum fetcher mock fetcher mock kinesis datum fetcher assume the give config be correct power mockito mock static kinesis config util class power mockito do nothing when kinesis config util class testable flink kinesis consumer consumer new testable flink kinesis consumer fake stream new property consumer open new configuration consumer run mockito mock source function source context class test suppress warning unchecked public void test fetcher should be correctly seed if restore from checkpoint throw exception setup initial state hash map stream shard handle sequence number fake restore state get fake restore store all mock operator state backend and initial state for initialize state testing list state tuple2 stream shard metadata sequence number list state new testing list state for map entry stream shard handle sequence number state fake restore state entry set list state add tuple2 of kinesis datum fetcher convert to stream shard metadata state get key state get value operator state store operator state store mock operator state store class when operator state store get union list state matcher any list state descriptor class then return list state state initialization context initialization context mock state initialization context class when initialization context get operator state store then return operator state store when initialization context be restore then return true mock fetcher kinesis datum fetcher mock fetcher mock kinesis datum fetcher list stream shard handle shard new array list shard add all fake restore state key set when mock fetcher discover new shard to subscribe then return shard assume the give config be correct power mockito mock static kinesis config util class power mockito do nothing when kinesis config util class start to test fetcher s initial state seed testable flink kinesis consumer consumer new testable flink kinesis consumer fake stream new property consumer initialize state initialization context consumer open new configuration consumer run mockito mock source function source context class for map entry stream shard handle sequence number restore shard fake restore state entry set mockito verify mock fetcher register new subscribe shard state new kinesis stream shard state kinesis datum fetcher convert to stream shard metadata restore shard get key restore shard get key restore shard get value test suppress warning unchecked public void test fetcher should be correctly seed only its own state throw exception setup initial state hash map stream shard handle sequence number fake restore state get fake restore store fake stream1 hash map stream shard handle sequence number fake restore state for other get fake restore store fake stream2 mock operator state backend and initial state for initialize state testing list state tuple2 stream shard metadata sequence number list state new testing list state for map entry stream shard handle sequence number state fake restore state entry set list state add tuple2 of kinesis datum fetcher convert to stream shard metadata state get key state get value for map entry stream shard handle sequence number state fake restore state for other entry set list state add tuple2 of kinesis datum fetcher convert to stream shard metadata state get key state get value operator state store operator state store mock operator state store class when operator state store get union list state matcher any list state descriptor class then return list state state initialization context initialization context mock state initialization context class when initialization context get operator state store then return operator state store when initialization context be restore then return true mock fetcher kinesis datum fetcher mock fetcher mock kinesis datum fetcher list stream shard handle shard new array list shard add all fake restore state key set when mock fetcher discover new shard to subscribe then return shard assume the give config be correct power mockito mock static kinesis config util class power mockito do nothing when kinesis config util class start to test fetcher s initial state seed testable flink kinesis consumer consumer new testable flink kinesis consumer fake stream new property consumer initialize state initialization context consumer open new configuration consumer run mockito mock source function source context class for map entry stream shard handle sequence number restore shard fake restore state for other entry set should never get restore state not belong to itself mockito verify mock fetcher never register new subscribe shard state new kinesis stream shard state kinesis datum fetcher convert to stream shard metadata restore shard get key restore shard get key restore shard get value for map entry stream shard handle sequence number restore shard fake restore state entry set should get restore state belong to itself mockito verify mock fetcher register new subscribe shard state new kinesis stream shard state kinesis datum fetcher convert to stream shard metadata restore shard get key restore shard get key restore shard get value this test that the consumer correctly pick up shard that be not discover on the previous run case under test if the original parallelism be and state be consumer subtask stream1 shard1 sequential number xxx consumer subtask stream1 shard2 sequential number yyy after discover new shard to subscribe if there be two shard shard3 shard4 create consumer subtask late for discover new shard to subscribe stream1 shard1 sequential number xxx consumer subtask stream1 shard2 sequential number yyy stream1 shard4 sequential number zzz if snapshot state occur and parallelism be change to union state will be stream1 shard1 sequential number xxx stream1 shard2 sequential number yyy stream1 shard4 sequential number zzz fetcher should be seed with stream1 shard1 sequential number xxx stream1 shard2 sequential number yyy stream1 share3 sentinel sequence number sentinel earliest sequence num stream1 shard4 sequential number zzz test suppress warning unchecked public void test fetcher should be correctly seed with new discover kinesis stream shard throw exception setup initial state hash map stream shard handle sequence number fake restore state get fake restore store all mock operator state backend and initial state for initialize state testing list state tuple2 stream shard metadata sequence number list state new testing list state for map entry stream shard handle sequence number state fake restore state entry set list state add tuple2 of kinesis datum fetcher convert to stream shard metadata state get key state get value operator state store operator state store mock operator state store class when operator state store get union list state matcher any list state descriptor class then return list state state initialization context initialization context mock state initialization context class when initialization context get operator state store then return operator state store when initialization context be restore then return true mock fetcher kinesis datum fetcher mock fetcher mock kinesis datum fetcher list stream shard handle shard new array list shard add all fake restore state key set shard add new stream shard handle fake stream2 new shard with shard id kinesis shard id generator generate from shard order when mock fetcher discover new shard to subscribe then return shard assume the give config be correct power mockito mock static kinesis config util class power mockito do nothing when kinesis config util class start to test fetcher s initial state seed testable flink kinesis consumer consumer new testable flink kinesis consumer fake stream new property consumer initialize state initialization context consumer open new configuration consumer run mockito mock source function source context class fake restore state put new stream shard handle fake stream2 new shard with shard id kinesis shard id generator generate from shard order sentinel sequence number sentinel earliest sequence num get for map entry stream shard handle sequence number restore shard fake restore state entry set mockito verify mock fetcher register new subscribe shard state new kinesis stream shard state kinesis datum fetcher convert to stream shard metadata restore shard get key restore shard get key restore shard get value test public void test legacy kinesis stream shard to stream shard metadata conversion string stream name fake stream1 string shard id shard string parent shard id shard string adjacent parent shard id shard string start hash key key string end hash key key string start sequence number seq string end sequence number seq stream shard metadata stream shard metadata new stream shard metadata stream shard metadata set stream name stream name stream shard metadata set shard id shard id stream shard metadata set parent shard id parent shard id stream shard metadata set adjacent parent shard id adjacent parent shard id stream shard metadata set start hash key start hash key stream shard metadata set end hash key end hash key stream shard metadata set start sequence number start sequence number stream shard metadata set end sequence number end sequence number shard shard new shard with shard id shard id with parent shard id parent shard id with adjacent parent shard id adjacent parent shard id with hash key range new hash key range with start hash key start hash key with end hash key end hash key with sequence number range new sequence number range with start sequence number start sequence number with end sequence number end sequence number kinesis stream shard kinesis stream shard new kinesis stream shard stream name shard assert equal stream shard metadata kinesis stream shard convert to stream shard metadata kinesis stream shard test public void test stream shard metadata serialize use pojo serializer type information stream shard metadata type information type information of stream shard metadata class assert true type information create serializer new execution config instanceof pojo serializer flink ensure that a state change in the stream shard metadata other than link stream shard metadata get shard id or link stream shard metadata get stream name do not result in the shard not be able to be restore this handle the corner case where the store shard metadata be open no ending sequence number but after the job restore the shard have be close end number set due to re sharding and we can no longer rely on link stream shard metadata equal object to find back the sequence number in the collection of restore shard metadata p p therefore we will rely on synchronize the snapshot s state with the kinesis shard before attempt to find back the sequence number to restore test public void test find sequence number to restore from if the shard have be close since the state be store throw exception setup initial state hash map stream shard handle sequence number fake restore state get fake restore store all mock operator state backend and initial state for initialize state testing list state tuple2 stream shard metadata sequence number list state new testing list state for map entry stream shard handle sequence number state fake restore state entry set list state add tuple2 of kinesis datum fetcher convert to stream shard metadata state get key state get value operator state store operator state store mock operator state store class when operator state store get union list state matcher any list state descriptor class then return list state state initialization context initialization context mock state initialization context class when initialization context get operator state store then return operator state store when initialization context be restore then return true mock fetcher kinesis datum fetcher mock fetcher mock kinesis datum fetcher list stream shard handle shard new array list create a fake stream shard handle base on the first entry in the restore state final stream shard handle original stream shard handle fake restore state key set iterator next final stream shard handle close stream shard handle new stream shard handle original stream shard handle get stream name original stream shard handle get shard close the shard handle by set a end sequence number final sequence number range sequence number range new sequence number range sequence number range set end sequence number close stream shard handle get shard set sequence number range sequence number range shard add closed stream shard handle when mock fetcher discover new shard to subscribe then return shard assume the give config be correct power mockito mock static kinesis config util class power mockito do nothing when kinesis config util class start to test fetcher s initial state seed testable flink kinesis consumer consumer new testable flink kinesis consumer fake stream new property consumer initialize state initialization context consumer open new configuration consumer run mockito mock source function source context class mockito verify mock fetcher register new subscribe shard state new kinesis stream shard state kinesis datum fetcher convert to stream shard metadata close stream shard handle close stream shard handle fake restore state get closed stream shard handle private static final class testing list state t implement list state t private final list t list new array list private boolean clear call false override public void clear list clear clear call true override public iterable t get throw exception return list override public void add t value throw exception list add value public list t get list return list public boolean be clear call return clear call override public void update list t value throw exception list clear add all value override public void add all list t value throw exception if value null list add all value private hash map stream shard handle sequence number get fake restore store string stream name hash map stream shard handle sequence number fake restore state new hash map if stream name equal fake stream1 stream name equal all fake restore state put new stream shard handle fake stream1 new shard with shard id kinesis shard id generator generate from shard order new sequence number uuid random u u i d to string fake restore state put new stream shard handle fake stream1 new shard with shard id kinesis shard id generator generate from shard order new sequence number uuid random u u i d to string fake restore state put new stream shard handle fake stream1 new shard with shard id kinesis shard id generator generate from shard order new sequence number uuid random u u i d to string if stream name equal fake stream2 stream name equal all fake restore state put new stream shard handle fake stream2 new shard with shard id kinesis shard id generator generate from shard order new sequence number uuid random u u i d to string fake restore state put new stream shard handle fake stream2 new shard with shard id kinesis shard id generator generate from shard order new sequence number uuid random u u i d to string return fake restore state private static kinesis datum fetcher mock kinesis datum fetcher throw exception kinesis datum fetcher mock fetcher mockito mock kinesis datum fetcher class java lang reflect constructor kinesis datum fetcher ctor java lang reflect constructor kinesis datum fetcher kinesis datum fetcher class get constructor class other param type new class ctor get parameter type length system arraycopy ctor get parameter type other param type ctor get parameter type length supplier object argument supplier object other param args new object other param type length for int i i other param type length i other param arg i mockito nullable other param type i return other param arg power mockito when new ctor with argument mockito any ctor get parameter type argument supplier get then return mock fetcher return mock fetcher test public void test periodic watermark throw exception string stream name fake stream name time max out of orderness time millisecond long auto watermark interval hash map string string subscribe stream to last discover shard id new hash map subscribe stream to last discover shard id put stream name null kinesis deserialization schema string deserialization schema new kinesis deserialization schema wrapper new simple string schema property prop new property prop set property consumer config constant aws region we east prop set property consumer config constant shard getrecord interval milli long to string 10 l block queue string shard1 new link blocking queue block queue string shard2 new link blocking queue map string list block queue string stream to queue map new hash map stream to queue map put stream name list new array list shard1 shard2 override create fetcher to mock kinesis flink kinesis consumer string source func new flink kinesis consumer string stream name deserialization schema prop override protect kinesis datum fetcher string create fetcher list string stream source context string source context runtime context runtime context property config prop kinesis deserialization schema string deserialization schema kinesis datum fetcher string fetcher new kinesis datum fetcher string stream source context source context get checkpoint lock runtime context config prop deserialization schema get shard assigner get periodic watermark assigner null new atomic reference new array list subscribe stream to last discover shard id prop fake kinesis behaviour factory block queue get record stream to queue map return fetcher source func set shard assigner stream shard handle i shard id return integer parse int stream shard handle get shard get shard id substr shard id length source func set periodic watermark assigner new test timestamp extractor max out of orderness there be currently no test harness specifically for source so we overlay the source thread here abstract stream operator test harness object test harness new abstract stream operator test harness object new stream source source func test harness set time characteristic time characteristic event time test harness get execution config set auto watermark interval auto watermark interval test harness initialize empty state test harness open concurrent link queue watermark watermark new concurrent link queue suppress warning unchecked source function source context string source context new collect source context test harness get checkpoint lock test harness get output override public void emit watermark watermark mark watermark add mark override public void mark as temporarily idle new thread try source func run source context catch interrupt exception e expect on cancel catch exception e throw new runtime exception e start shard1 put shard1 put shard2 put int record count int watermark count await record count test harness get output record count trigger watermark emit test harness set processing time test harness get processing time auto watermark interval watermark count advance watermark shard1 put record count await record count test harness get output record count trigger watermark emit test harness set processing time test harness get processing time auto watermark interval watermark count source func cancel test harness close assert equal record count record count test harness get output size assert equal watermark count watermark count watermark size assert that watermark org hamcrest matcher contain new watermark new watermark test public void test source synchronization throw exception final string stream name fake stream name final time max out of orderness time millisecond final long auto watermark interval final long watermark sync interval auto watermark interval test watermark tracker watermark set hash map string string subscribe stream to last discover shard id new hash map subscribe stream to last discover shard id put stream name null final kinesis deserialization schema string deserialization schema new kinesis deserialization schema wrapper new open checking string schema property prop new property prop set property consumer config constant aws region we east prop set property consumer config constant shard getrecord interval milli long to string 10 l prop set property consumer config constant watermark sync milli long to string watermark sync interval prop set property consumer config constant watermark lookahead milli long to string block queue string shard1 new link blocking queue map string list block queue string stream to queue map new hash map stream to queue map put stream name collection singleton list shard1 override create fetcher to mock kinesis flink kinesis consumer string source func new flink kinesis consumer string stream name deserialization schema prop override protect kinesis datum fetcher string create fetcher list string stream source function source context string source context runtime context runtime context property config prop kinesis deserialization schema string deserialization schema kinesis datum fetcher string fetcher new kinesis datum fetcher string stream source context source context get checkpoint lock runtime context config prop deserialization schema get shard assigner get periodic watermark assigner get watermark tracker new atomic reference new array list subscribe stream to last discover shard id prop fake kinesis behaviour factory block queue get record stream to queue map override protect void emit watermark necessary in this test to ensure that watermark state be update before the watermark timer callback be trigger synchronize source context get checkpoint lock super emit watermark return fetcher source func set shard assigner stream shard handle i shard id return integer parse int stream shard handle get shard get shard id substr shard id length source func set periodic watermark assigner new test timestamp extractor max out of orderness source func set watermark tracker new test watermark tracker there be currently no test harness specifically for source so we overlay the source thread here abstract stream operator test harness object test harness new abstract stream operator test harness object new stream source source func test harness set time characteristic time characteristic event time test harness get execution config set auto watermark interval auto watermark interval test harness initialize empty state test harness open final concurrent link queue object result test harness get output final atomic boolean throw on collect new atomic boolean suppress warning unchecked source function source context string source context new collect source context test harness get checkpoint lock result override public void mark as temporarily idle override public void collect serializable element if throw on collect get throw new runtime exception expect super collect element override public void emit watermark watermark mark result add mark final atomic reference exception source thread error new atomic reference new thread try source func run source context catch interrupt exception e expect on cancel catch exception e source thread error set e start array list object expect result new array list final long record1 shard1 put long to string record1 expect result add long to string record1 await record count result expect result size at this point we know the fetcher be initialize final kinesis datum fetcher fetcher org powermock reflect whitebox get internal state source func fetcher trigger watermark emit test harness set processing time test harness get processing time auto watermark interval expect result add new watermark verify watermark await record count result expect result size assert that result org hamcrest matcher contain expect result to array assert equal test watermark tracker watermark get trigger sync test harness set processing time test harness get processing time test watermark tracker assert global watermark final long record2 record1 watermark sync interval shard1 put long to string record2 wait for the record to be buffer in the emitter final record emitter emitter org powermock reflect whitebox get internal state fetcher record emitter record emitter record queue emitter queue emitter get queue deadline deadline deadline from now duration of seconds while deadline have time leave emitter queue get size thread sleep assert equal first record receive emitter queue get size advance the watermark since the new record be past global watermark threshold it win t be emit and the watermark do not advance test harness set processing time test harness get processing time auto watermark interval assert that result org hamcrest matcher contain expect result to array assert equal l long org powermock reflect whitebox get internal state fetcher next watermark test watermark tracker assert global watermark trigger global watermark sync test harness set processing time test harness get processing time expect result add long to string record2 await record count result expect result size assert that result org hamcrest matcher contain expect result to array test watermark tracker assert global watermark trigger watermark update and emit test harness set processing time test harness get processing time auto watermark interval expect result add new watermark assert that result org hamcrest matcher contain expect result to array verify exception propagation assert assert null source thread error get throw on collect set true shard1 put long to string record2 deadline deadline from now duration of seconds while deadline have time leave source thread error get null thread sleep assert assert not null source thread error get assert assert not null expect source thread error get get message source func cancel test harness close private void await record count concurrent link queue extend object queue int count throw exception deadline deadline deadline from now duration of seconds while deadline have time leave queue size count thread sleep private static class open checking string schema extend simple string schema private boolean open false override public void open deserialization schema initialization context context throw exception assert that context get metric group not null value metric group class this open true override public string deserialize byte message if open throw new assertion error deserialization schema be not open before deserialization return super deserialize message private static class test timestamp extractor extend bound out of orderness timestamp extractor string private static final long serial version u i d 1 l public test timestamp extractor time max allow lateness super max allow lateness override public long extract timestamp string element return long parse long element private static class test watermark tracker extend watermark tracker private static final atomic long watermark new atomic long override public long get update timeout count return override public long update watermark long local watermark watermark set local watermark return local watermark static void assert global watermark long expect assert assert equal expect watermark get 
a w s util test run with power mock runner class prepare for test a w s util class public class a w s util test rule private final expect exception exception expect exception none test public void test default credentials provider property test config new property a w s credentials provider credentials provider a w s util get credentials provider test config assert true credentials provider instanceof default a w s credentials provider chain test public void test get credentials provider property test config new property test config set property a w s config constant aws credentials provider web identity token a w s credentials provider credentials provider a w s util get credentials provider test config assert true credentials provider instanceof web identity token credentials provider test public void test invalid credentials provider exception expect illegal argument exception class property test config new property test config set property a w s config constant aws credentials provider invalid provider a w s util get credentials provider test config test public void test valid region assert true a w s util be valid region we east test public void test invalid region assert false a w s util be valid region ur east 
kinesis config util test run with power mock runner class prepare for test kinesis config util class public class kinesis config util test rule private expected exception exception expect exception none get validate producer configuration test test public void test unparsable long for producer configuration exception expect illegal argument exception class exception expect message error try to set field rate limit with the value unparsable long property test config new property test config set property a w s config constant aws region we east test config set property rate limit unparsable long kinesis config util get validate producer configuration test config test public void test rate limit in producer configuration property test config new property test config set property a w s config constant aws region we east kinesis producer configuration kpc kinesis config util get validate producer configuration test config assert equal kpc get rate limit test config set property kinesis config util rate limit kpc kinesis config util get validate producer configuration test config assert equal kpc get rate limit test public void test threading model in producer configuration property test config new property test config set property a w s config constant aws region we east kinesis producer configuration kpc kinesis config util get validate producer configuration test config assert equal kinesis producer configuration threading model pool kpc get thread model test config set property kinesis config util threading model per request kpc kinesis config util get validate producer configuration test config assert equal kinesis producer configuration threading model per request kpc get thread model test public void test thread pool size in producer configuration property test config new property test config set property a w s config constant aws region we east kinesis producer configuration kpc kinesis config util get validate producer configuration test config assert equal kpc get thread pool size test config set property kinesis config util thread pool size kpc kinesis config util get validate producer configuration test config assert equal kpc get thread pool size test public void test replace deprecate key property test config new property test config set property a w s config constant aws region we east these deprecate key should be replace test config set property producer config constant aggregation max count test config set property producer config constant collection max count property replace config kinesis config util replace deprecate producer key test config assert equal replace config get property kinesis config util aggregation max count assert equal replace config get property kinesis config util collection max count test public void test correctly set region in producer configuration string region we east property test config new property test config set property a w s config constant aws region region kinesis producer configuration kpc kinesis config util get validate producer configuration test config assert equal incorrect region region kpc get region test public void test miss aws region in producer config string expect message string format for flink kinesis producer aws region s must be set in the config a w s config constant aws region exception expect illegal argument exception class exception expect message expect message property test config new property test config set property a w s config constant aw access key id access key test config set property a w s config constant aw secret access key secret key kinesis config util get validate producer configuration test config validate aws configuration test test public void test unrecognizable aws region in config exception expect illegal argument exception class exception expect message invalid aws region property test config new property test config set property a w s config constant aws region wrong region id test config set property a w s config constant aw access key id access key id test config set property a w s config constant aw secret access key secret key kinesis config util validate aws configuration test config test public void test credential provider type set to basic but no credential set in config exception expect illegal argument exception class exception expect message please set value for aws access key id a w s config constant aw access key id and secret key a w s config constant aw secret access key when use the basic aws credential provider type property test config new property test config set property a w s config constant aws region we east test config set property a w s config constant aws credentials provider basic kinesis config util validate aws configuration test config test public void test unrecognizable credential provider type in config exception expect illegal argument exception class exception expect message invalid aws credential provider type property test config test util get standard property test config set property a w s config constant aws credentials provider wrong provider type kinesis config util validate aws configuration test config validate consumer configuration test test public void test no aws region or endpoint in consumer config string expect message string format for flink kinesis consumer aws region s and or aws endpoint s must be set in the config a w s config constant aws region a w s config constant aw endpoint exception expect illegal argument exception class exception expect message expect message property test config new property test config set property a w s config constant aw access key id access key test config set property a w s config constant aw secret access key secret key kinesis config util validate consumer configuration test config test public void test aws region and endpoint in consumer config property test config new property test config set property a w s config constant aws region we east test config set property a w s config constant aws endpoint fake test config set property a w s config constant aw access key id access key test config set property a w s config constant aw secret access key secret key kinesis config util validate consumer configuration test config test public void test aws region in consumer config property test config new property test config set property a w s config constant aws region we east test config set property a w s config constant aw access key id access key test config set property a w s config constant aw secret access key secret key kinesis config util validate consumer configuration test config test public void test endpoint in consumer config property test config new property test config set property a w s config constant aws endpoint fake test config set property a w s config constant aw access key id access key test config set property a w s config constant aw secret access key secret key kinesis config util validate consumer configuration test config test public void test unrecognizable stream init position type in config exception expect illegal argument exception class exception expect message invalid initial position in stream property test config test util get standard property test config set property consumer config constant aws credentials provider basic test config set property consumer config constant stream initial position wrong init position kinesis config util validate consumer configuration test config test public void test stream init position type set to at timestamp but no init timestamp set in config exception expect illegal argument exception class exception expect message please set value for initial timestamp consumer config constant stream initial timestamp when use at timestamp initial position property test config test util get standard property test config set property consumer config constant aws credentials provider basic test config set property consumer config constant stream initial position at timestamp kinesis config util validate consumer configuration test config test public void test unparsable date for initial timestamp in config exception expect illegal argument exception class exception expect message invalid value give for initial timestamp for at timestamp initial position in stream property test config test util get standard property test config set property consumer config constant aws credentials provider basic test config set property consumer config constant stream initial position at timestamp test config set property consumer config constant stream initial timestamp unparsable date kinesis config util validate consumer configuration test config test public void test illegal value for initial timestamp in config exception expect illegal argument exception class exception expect message invalid value give for initial timestamp for at timestamp initial position in stream property test config test util get standard property test config set property consumer config constant aws credentials provider basic test config set property consumer config constant stream initial position at timestamp test config set property consumer config constant stream initial timestamp 1.0 kinesis config util validate consumer configuration test config test public void test date string for validate option date property string timestamp 2016 - 04 04 t19 58:46 480 - 00 property test config test util get standard property test config set property consumer config constant aws credentials provider basic test config set property consumer config constant stream initial position at timestamp test config set property consumer config constant stream initial timestamp timestamp try kinesis config util validate consumer configuration test config catch exception e e print stack trace fail test public void test unix timestamp for validate option date property string unix timestamp 1459799926.480 property test config test util get standard property test config set property consumer config constant aws credentials provider basic test config set property consumer config constant stream initial position at timestamp test config set property consumer config constant stream initial timestamp unix timestamp try kinesis config util validate consumer configuration test config catch exception e e print stack trace fail test public void test invalid pattern for initial timestamp in config exception expect illegal argument exception class exception expect message invalid value give for initial timestamp for at timestamp initial position in stream property test config test util get standard property test config set property consumer config constant aws credentials provider basic test config set property consumer config constant stream initial position at timestamp test config set property consumer config constant stream initial timestamp 2016 - 03 test config set property consumer config constant stream timestamp date format invalid pattern kinesis config util validate consumer configuration test config test public void test unparsable date for user define date format for initial timestamp in config exception expect illegal argument exception class exception expect message invalid value give for initial timestamp for at timestamp initial position in stream property test config test util get standard property test config set property consumer config constant aws credentials provider basic test config set property consumer config constant stream initial position at timestamp test config set property consumer config constant stream initial timestamp still unparsable test config set property consumer config constant stream timestamp date format yyyy mm dd kinesis config util validate consumer configuration test config test public void test date string for user define date format for validate option date property string unix timestamp 2016 - 04 string pattern yyyy mm dd property test config test util get standard property test config set property consumer config constant aws credentials provider basic test config set property consumer config constant stream initial position at timestamp test config set property consumer config constant stream initial timestamp unix timestamp test config set property consumer config constant stream timestamp date format pattern kinesis config util validate consumer configuration test config test public void test unparsable long for list shard backoff base milli in config exception expect illegal argument exception class exception expect message invalid value give for list shard operation base backoff millisecond property test config test util get standard property test config set property consumer config constant list shard backoff base unparsable long kinesis config util validate consumer configuration test config test public void test unparsable long for list shard backoff max millis in config exception expect illegal argument exception class exception expect message invalid value give for list shard operation max backoff millisecond property test config test util get standard property test config set property consumer config constant list shard backoff max unparsable long kinesis config util validate consumer configuration test config test public void test unparsable double for list shard backoff exponential constant in config exception expect illegal argument exception class exception expect message invalid value give for list shard operation backoff exponential constant property test config test util get standard property test config set property consumer config constant list shard backoff exponential constant unparsable double kinesis config util validate consumer configuration test config test public void test unparsable int for get record retry in config exception expect illegal argument exception class exception expect message invalid value give for maximum retry attempt for get record shard operation property test config test util get standard property test config set property consumer config constant shard getrecord retry unparsable int kinesis config util validate consumer configuration test config test public void test unparsable int for get record max count in config exception expect illegal argument exception class exception expect message invalid value give for maximum record per get record shard operation property test config test util get standard property test config set property consumer config constant shard getrecord max unparsable int kinesis config util validate consumer configuration test config test public void test unparsable long for get record backoff base milli in config exception expect illegal argument exception class exception expect message invalid value give for get record operation base backoff millisecond property test config test util get standard property test config set property consumer config constant shard getrecord backoff base unparsable long kinesis config util validate consumer configuration test config test public void test unparsable long for get record backoff max millis in config exception expect illegal argument exception class exception expect message invalid value give for get record operation max backoff millisecond property test config test util get standard property test config set property consumer config constant shard getrecord backoff max unparsable long kinesis config util validate consumer configuration test config test public void test unparsable double for get record backoff exponential constant in config exception expect illegal argument exception class exception expect message invalid value give for get record operation backoff exponential constant property test config test util get standard property test config set property consumer config constant shard getrecord backoff exponential constant unparsable double kinesis config util validate consumer configuration test config test public void test unparsable long for get record interval millis in config exception expect illegal argument exception class exception expect message invalid value give for get record sleep interval in millisecond property test config test util get standard property test config set property consumer config constant shard getrecord interval millis unparsable long kinesis config util validate consumer configuration test config test public void test unparsable int for get shard iterator retry in config exception expect illegal argument exception class exception expect message invalid value give for maximum retry attempt for get shard iterator shard operation property test config test util get standard property test config set property consumer config constant shard getiterator retry unparsable int kinesis config util validate consumer configuration test config test public void test unparsable long for get shard iterator backoff base millis in config exception expect illegal argument exception class exception expect message invalid value give for get shard iterator operation base backoff millisecond property test config test util get standard property test config set property consumer config constant shard getiterator backoff base unparsable long kinesis config util validate consumer configuration test config test public void test unparsable long for get shard iterator backoff max millis in config exception expect illegal argument exception class exception expect message invalid value give for get shard iterator operation max backoff millisecond property test config test util get standard property test config set property consumer config constant shard getiterator backoff max unparsable long kinesis config util validate consumer configuration test config test public void test unparsable double for get shard iterator backoff exponential constant in config exception expect illegal argument exception class exception expect message invalid value give for get shard iterator operation backoff exponential constant property test config test util get standard property test config set property consumer config constant shard getiterator backoff exponential constant unparsable double kinesis config util validate consumer configuration test config test public void test unparsable long for shard discovery interval millis in config exception expect illegal argument exception class exception expect message invalid value give for shard discovery sleep interval in millisecond property test config test util get standard property test config set property consumer config constant shard discovery interval millis unparsable long kinesis config util validate consumer configuration test config 
init output path test run with power mock runner class prepare for test local file system class public class init output path test rule public final temporary folder temp dir new temporary folder this test validate that this test case make sense that the error can be produce in the absence of synchronization if the thread make progress in a certain way here enforce by latch test public void test error occur un synchronize throw exception deactivate the lock to produce the original un synchronize state field lock file system class get declare field output directory init lock lock set accessible true lock set null new no op lock try in the original un synchronize state we can force the race to occur by use the proper latch order to control the process of the concurrent thread run test true fail should fail with a exception catch file not find exception e expect finally reset the proper value lock set null new reentrant lock true test public void test proper synchronize throw exception in the synchronize variant we can not use the await latch because not both thread can make process interleave due to the synchronization the test use sleep rather than latch to produce the same interleaving while that be not guarantee to produce the pathological interleave it help to provoke it very often together with validate that this order be in fact pathological see test error occur un synchronize this give a rather confident guard run test false private void run test final boolean use await throw exception final file temp file temp dir new file final path path1 new path temp file get absolute path final path path2 new path temp file get absolute path final one shot latch delete await latch1 new one shot latch final one shot latch delete await latch2 new one shot latch final one shot latch mkdir await latch1 new one shot latch final one shot latch mkdir await latch2 new one shot latch final one shot latch delete trigger latch1 new one shot latch final one shot latch deletetrigger latch2 new one shot latch final one shot latch mkdir trigger latch1 new one shot latch final one shot latch mkdir trigger latch2 new one shot latch final one shot latch create await latch new one shot latch final one shot latch create trigger latch new one shot latch this new local datum output stream be in the end call by the async thread when new local datum output stream class with any argument then answer new answer local datum output stream override public local datum output stream answer invocation on mock invocation throw throwable create await latch trigger create trigger latch await final file file file invocation get argument return new local datum output stream file final local file system fs1 new synced file system delete await latch1 mkdir await latch1 delete trigger latch1 mkdir trigger latch1 final local file system fs2 new synced file system delete await latch2 mkdir await latch2 deletetrigger latch2 mkdir trigger latch2 start the concurrent file creator file creator thread1 new file creator fs1 path1 file creator thread2 new file creator fs2 path2 thread1 start thread2 start wait until they both decide to delete the directory if use await delete await latch1 await delete await latch2 await else thread sleep now send off to delete the directory it will pass the mkdir fast and wait to create the file mkdir trigger latch1 trigger delete trigger latch1 trigger if use await create await latch await else this need a bit more sleep time because here mockito be work thread sleep now send off to delete the directory it wait at mkdir deletetrigger latch2 trigger if use await mkdir await latch2 await else thread sleep let try to create the file and see if it succeed create trigger latch trigger if use await thread1 sync else thread sleep now let finish up mkdir trigger latch2 trigger thread1 sync thread2 sync private static class file creator extend check thread private final file system f private final path path file creator file system f path path this f fs this path path override public void go throw exception fs init out path local f s path get parent write mode overwrite true try f s datum output stream out f create path write mode overwrite out write private static class synce file system extend local file system private final one shot latch delete trigger latch private final one shot latch mkdir trigger latch private final one shot latch delete await latch private final one shot latch mkdir await latch synce file system one shot latch delete trigger latch one shot latch mkdir trigger latch one shot latch delete await latch one shot latch mkdir await latch this delete trigger latch delete trigger latch this mkdir trigger latch mkdir trigger latch this delete await latch delete await latch this mkdir await latch mkdir await latch override public boolean delete path f boolean recursive throw i o exception delete trigger latch trigger try delete await latch await catch interrupted exception e thread current thread interrupt throw new i o exception interrupt return super delete f recursive override public boolean mkdir path f throw i o exception mkdir trigger latch trigger try mkdir await latch await catch interrupted exception e thread current thread interrupt throw new i o exception interrupt return super mkdir f suppress warning serial private static final class no op lock extend reentrant lock override public void lock override public void lock interruptibly override public void unlock 
rock d b init test run with power mock runner class prepare for test rock d b class public class rock d b init test rule public final temporary folder temporary folder new temporary folder this test check that the rock d b native code loader still respond to reset the init flag test public void test reset init flag throw exception rock d b state backend reset rock d b loaded flag test public void test temp lib folder delete on fail throw exception power mockito spy rock d b class power mockito when rock d b class load library then throw new expected test exception file temp folder temporary folder new folder try rock d b state backend ensure rock d b be load temp folder get absolute path fail not throw expect exception catch i o exception ignore ignore file file temp folder list file assert assert not null file assert assert equal file length 
rock d b memory controller util test run with power mock runner class prepare for test rock d b memory controller util class public class rock d b memory controller util test rule public final temporary folder temporary folder new temporary folder before public void ensure rock db native library load throw i o exception native library loader get instance load library temporary folder new folder get absolute path test public void test create share resource with expect capacity power mockito mock static rock d b memory controller util class final atomic long actual cache capacity new atomic long 0 l final atomic long actual wbm capacity new atomic long 0 l when rock d b memory controller util allocate rock d b share resource any long any double any double then call real method when rock d b memory controller util calculate actual cache capacity any long any double then call real method when rock d b memory controller util calculate write buffer manager capacity any long any double then call real method because power mockito can not mock on native static method easily we introduce create cache and create write buffer manager wrapper here when rock d b memory controller util create cache any long any double then answer answer l r u cache invocation object argument invocation get argument actual cache capacity set long argument return l r u cache invocation call real method when rock d b memory controller util create write buffer manager any long any cache class then answer answer write buffer manager invocation object argument invocation get argument actual wbm capacity set long argument return write buffer manager invocation call real method long total memory size l double write buffer ratio 0.5 double high pri pool ratio 0.1 rock d b memory controller util allocate rock d b share resource total memory size write buffer ratio high pri pool ratio long expect cache capacity rock d b memory controller util calculate actual cache capacity total memory size write buffer ratio long expect wbm capacity rock d b memory controller util calculate write buffer manager capacity total memory size write buffer ratio assert that actual cache capacity get be expect cache capacity assert that actual wbm capacity get be expect wbm capacity 
