h base input format experimental public abstract class h base input format t extend tuple extend abstract table input format t private static final long serial version u i d 1 l construct a link input format with hbase configuration to read datum from hbase param h conf the configuration that connect to hbase at least hbase zookeeper quorum and zookeeper znode parent need to be set public h base input format org apache hadoop conf configuration h conf super h conf return a instance of scan that retrieve the require subset of record from the h base table return the appropriate instance of scan for this usecase protect abstract scan get scanner what table be to be read per instance of a table input format derivative only a single tablename be possible return the name of the table protect abstract string get table name the output from h base be always a instance of link result this method be to copy the datum in the result instance into the require link tuple param be the result instance from h base that need to be convert return the appropriate instance of link tuple that contain the need information protect abstract t map result to tuple result r create a link scan object and open the link h table connection these be open here because they be need in the create input splits which be call before the open input format method so the connection be open in link configure configuration and close in link close input format param parameter the configuration that be to be use see configuration override public void configure configuration parameter table create table if table null scan get scanner create a link h table instance and set it into this format private h table create table log info initialize h base configuration org apache hadoop conf configuration h conf get hadoop configuration try return new h table h conf get table name catch exception e log error error instantiate a new h table instance e return null protected t map result to out type result r return map result to tuple r 
jdbc input format experimental public class jdbc input format extend rich input format row input split implement result type queryable row protect static final long serial version u i d 1 l protect static final logger log logger factory get logger jdbc input format class protect string username protect string password protect string drivername protect string db u r l protect string query template protect int result set type protect int result set concurrency protect row type info row type info protect transient connection db conn protect transient prepared statement statement protect transient result set result set protect int fetch size boolean to distinguish between default value and explicitly set auto commit mode protect boolean auto commit protect boolean have next protected object parameter value public jdbc input format override public row type info get produce type return row type info override public void configure configuration parameter do nothing here override public void open input format call once per input format on open try class for name drivername if username null db conn driver manager get connection db u r l else db conn driver manager get connection db u r l username password set auto commit mode only if it be explicitly configure keep connection default otherwise if auto commit null db conn set auto commit auto commit statement db conn prepare statement query template result set type result set concurrency if fetch size integer min value fetch size statement set fetch size fetch size catch s q l exception se throw new illegal argument exception open fail se get message se catch class not find exception cnfe throw new illegal argument exception jdbc class not find cnfe get message cnfe override public void close input format call once per input format on close try if statement null statement close catch s q l exception se log info inputformat statement couldn t be close se get message finally statement null try if db conn null db conn close catch s q l exception se log info inputformat couldn t be close se get message finally db conn null parameter value null connect to the source database and execute the query in a b parallel fashion b if this link input format be build use a parameterized query i e use a link prepared statement and a proper link jdbc parameter value provider in a b non parallel fashion b otherwise param input split which be ignore if this input format be execute as a non parallel source a hook to the query parameter otherwise use its i split number i throw i o exception if there be a error during the execution of the query override public void open input split input split throw i o exception try if input split null parameter value null for int i i parameter value input split get split number length i object param parameter value input split get split number i if param instanceof string statement set string i string param else if param instanceof long statement set long i long param else if param instanceof integer statement set int i integer param else if param instanceof double statement set double i double param else if param instanceof boolean statement set boolean i boolean param else if param instanceof float statement set float i float param else if param instanceof big decimal statement set big decimal i big decimal param else if param instanceof byte statement set byte i byte param else if param instanceof short statement set short i short param else if param instanceof date statement set date i date param else if param instanceof time statement set time i time param else if param instanceof timestamp statement set timestamp i timestamp param else if param instanceof array statement set array i array param else extend with other type if need throw new illegal argument exception open fail parameter i of type param get class be not handle yet if log be debug enable log debug string format execute s with parameter s query template array deep to string parameter value input split get split number result set statement execute query have next result set next catch s q l exception se throw new illegal argument exception open fail se get message se close all resource use throw i o exception indicate that a resource could not be closed override public void close throw i o exception if result set null return try result set close catch s q l exception se log info inputformat result set couldn t be close se get message check whether all datum have be read return boolean value indication whether all datum have be read throw i o exception override public boolean reach end throw i o exception return have next store the next result set row in a tuple param reuse row to be reuse return row contain next link row throw i o exception override public row next record row reuse throw i o exception try if have next return null for int pos po reuse get arity po reuse set field po result set get object po update have next after we have read the record have next result set next return reuse catch s q l exception se throw new i o exception couldn t read datum se get message se catch null pointer exception npe throw new i o exception couldn t access result set npe override public base statistics get statistics base statistics cache statistics throw i o exception return cache statistics override public input split create input split int min num split throw i o exception if parameter value null return new generic input split new generic input split generic input split ret new generic input split parameter value length for int i i ret length i ret i new generic input split i ret length return ret override public input split assigner get input split assigner input split input split return new default input split assigner input split visible for testing protect prepared statement get statement return statement visible for testing protect connection get db conn return db conn a builder use to set parameter to the output format s configuration in a fluent way return builder public static jdbc input format builder build jdbc input format return new jdbc input format builder builder for link jdbc input format public static class jdbc input format builder private final jdbc input format format public jdbc input format builder this format new jdbc input format use type forward only for high performance read this format result set type result set type forward only this format result set concurrency result set concur read only public jdbc input format builder set username string username format username username return this public jdbc input format builder set password string password format password password return this public jdbc input format builder set drivername string drivername format drivername drivername return this public jdbc input format builder set d b url string db u r l format db u r l db u r l return this public jdbc input format builder set query string query format query template query return this public jdbc input format builder set result set type int result set type format result set type result set type return this public jdbc input format builder set result set concurrency int result set concurrency format result set concurrency result set concurrency return this public jdbc input format builder set parameter provider jdbc parameter value provider parameter value provider format parameter value parameter value provider get parameter value return this public jdbc input format builder set row type info row type info row type info format row type info row type info return this public jdbc input format builder set fetch size int fetch size precondition check argument fetch size integer min value fetch size illegal value be for fetch size have to be positive or integer min value fetch size format fetch size fetch size return this public jdbc input format builder set auto commit boolean auto commit format auto commit auto commit return this public jdbc input format finish if format username null log info username be not supply separately if format password null log info password be not supply separately if format db u r l null throw new illegal argument exception no database url supply if format query template null throw new illegal argument exception no query supply if format drivername null throw new illegal argument exception no driver supply if format row type info null throw new illegal argument exception no row type info class get simple name supply if format parameter value null log debug no input splitting configure datum will be read with parallelism return format 
jdbc output format experimental public class jdbc output format extend jdbc batching output format row row jdbc batch statement executor row private static final long serial version u i d 1 l private static final logger log logger factory get logger jdbc output format class private jdbc output format jdbc connection provider connection provider string sql int type array int batch size super connection provider new jdbc execution option builder with batch size batch size build ctx create row executor sql type array ctx jdbc batch output format record extractor identity private static jdbc batch statement executor row create row executor string sql int type array runtime context ctx jdbc statement builder row statement builder st record set record to statement st type array record return jdbc batch statement executor simple sql statement builder ctx get execution config be object reuse enable row copy function identity public static jdbc output format builder build jdbc output format return new jdbc output format builder builder for link jdbc output format public static class jdbc output format builder private string username private string password private string drivername private string db u r l private string query private int batch size jdbc execution option default size private int type array private jdbc output format builder public jdbc output format builder set username string username this username username return this public jdbc output format builder set password string password this password password return this public jdbc output format builder set drivername string drivername this drivername drivername return this public jdbc output format builder set d b url string db u r l this db u be l db u r l return this public jdbc output format builder set query string query this query query return this public jdbc output format builder set batch size int batch size this batch size batch size return this public jdbc output format builder set sql type int type array this type array type array return this finalize the configuration and check validity return configure jdbc output format public jdbc output format finish return new jdbc output format new simple jdbc connection provider build connection option query type array batch size public jdbc connection option build connection option if this username null log info username be not supply if this password null log info password be not supply return new jdbc connection option jdbc connection option builder with url db u r l with driver name drivername with username username with password password build 
jdbc generic parameter value provider experimental public class jdbc generic parameter value provider implement jdbc parameter value provider private final serializable parameter public jdbc generic parameter value provider serializable parameter this parameter parameter override public serializable get parameter value do nothing precomputed externally return parameter 
jdbc numeric between parameter provider experimental public class jdbc numeric between parameter provider implement jdbc parameter value provider private final long min val private final long max val private long batch size private int batch num numeric between parameter provider jdbc constructor param min val the lower bind of the produce from value param max val the upper bind of the produce to value public jdbc numeric between parameter provider long min val long max val precondition check argument min val max val min val must not be larger than max val this min val min val this max val max val numeric between parameter provider jdbc constructor param fetch size the max distance between the produce from to pair param min val the lower bind of the produce from value param max val the upper bind of the produce to value public jdbc numeric between parameter provider long fetch size long min val long max val precondition check argument min val max val min val must not be larger than max val this min val min val this max val max val of batch size fetch size public jdbc numeric between parameter provider of batch size long batch size precondition check argument batch size batch size must be positive long max elem count max val min val if batch size max elem count batch size max elem count this batch size batch size this batch num new double math ceil double max elem count batch size int value return this public jdbc numeric between parameter provider of batch num int batch num precondition check argument batch num batch number must be positive long max elem count max val min val if batch num max elem count batch num int max elem count this batch num batch num this batch size new double math ceil double max elem count batch num long value return this override public serializable get parameter value precondition check state batch size batch size and batch number must be positive have you call of batch size or of batch num long max elem count max val min val long big batch num max elem count batch size batch num serializable parameter new serializable batch num long start min val for int i i batch num i long end start batch size i big batch num parameter i new long start end start end return parameter 
jdbc parameter value provider experimental public interface jdbc parameter value provider return the necessary parameter array to use for query in parallel a table serializable get parameter value 
flink kafka shuffle experimental public class flink kafka shuffle static final string producer parallelism producer parallelism static final string partition number partition number use kafka as a message bus to persist key by shuffle p persist key by shuffle be achieve by wrap a link flink kafka shuffle producer and link flink kafka shuffle consumer together p on the producer side link flink kafka shuffle producer be similar to link datum stream key by key selector they use the same key group assignment function link key group range assignment assign key to parallel operator to decide which partition a key go hence each producer task can potentially write to each kafka partition base on where the key go here number of partition equal to the key group size in the case of use link time characteristic event time each producer task broadcast its watermark to all of the kafka partition to make sure watermark information be propagate correctly p on the consumer side each consumer task should read partition equal to the key group index it be assign number of partition be the maximum parallelism of the consumer this version only support number of partition consumer parallelism in the case of use link time characteristic event time a consumer task be responsible to emit watermark watermark be read from the correspond kafka partition notice that a consumer task only start to emit a watermark after read at least one watermark from each producer task to make sure watermark be monotonically increase hence a consumer task need to know producer parallelism as well see flink kafka shuffle write key by see flink kafka shuffle read key by param datum stream datum stream to be shuffle param topic kafka topic write to param producer parallelism parallelism of producer param number of partition number of partition param property kafka property param key selector key selector to retrieve key from datum stream param t type of the input datum stream param k type of key public static t k keyed stream t k persistent key by datum stream t datum stream string topic int producer parallelism int number of partition property property key selector t k key selector kafka producer prop to map use property purely as a hash map without consider the default property so we have to flatten the default property to first level element property kafka property property util flatten property kafka property set property producer parallelism string value of producer parallelism kafka property set property partition number string value of number of partition stream execution environment env datum stream get execution environment write key by datum stream topic kafka property key selector return read key by topic env datum stream get type kafka property key selector use kafka as a message bus to persist key by shuffle p persist key by shuffle be achieve by wrap a link flink kafka shuffle producer and link flink kafka shuffle consumer together p on the producer side link flink kafka shuffle producer be similar to link datum stream key by key selector they use the same key group assignment function link key group range assignment assign key to parallel operator to decide which partition a key go hence each producer task can potentially write to each kafka partition base on where the key go here number of partition equal to the key group size in the case of use link time characteristic event time each producer task broadcast its watermark to all of the kafka partition to make sure watermark information be propagate correctly p on the consumer side each consumer task should read partition equal to the key group index it be assign number of partition be the maximum parallelism of the consumer this version only support number of partition consumer parallelism in the case of use link time characteristic event time a consumer task be responsible to emit watermark watermark be read from the correspond kafka partition notice that a consumer task only start to emit a watermark after read at least one watermark from each producer task to make sure watermark be monotonically increase hence a consumer task need to know producer parallelism as well see flink kafka shuffle write key by see flink kafka shuffle read key by param datum stream datum stream to be shuffle param topic kafka topic write to param producer parallelism parallelism of producer param number of partition number of partition param property kafka property param field key position from the input datum stream param t type of the input datum stream public static t key stream t tuple persistent key by datum stream t datum stream string topic int producer parallelism int number of partition property property int field return persistent key by datum stream topic producer parallelism number of partition property key selector datum stream field the write side of link flink kafka shuffle persistent key by p this function contain a link flink kafka shuffle producer to shuffle and persist datum in kafka link flink kafka shuffle producer use the same key group assignment function link key group range assignment assign key to parallel operator to decide which partition a key go hence each producer task can potentially write to each kafka partition base on the key here the number of partition equal to the key group size in the case of use link time characteristic event time each producer task broadcast each watermark to all of the kafka partition to make sure watermark information be propagate properly p attention make sure kafka property include link flink kafka shuffle producer parallelism and link flink kafka shuffle partition number explicitly link flink kafka shuffle producer parallelism be the parallelism of the producer link flink kafka shuffle partition number be the number of partition they be not necessarily the same and allow to be set independently see flink kafka shuffle persistent key by see flink kafka shuffle read key by param datum stream datum stream to be shuffle param topic kafka topic write to param kafka property kafka property for kafka producer param key selector key selector to retrieve key from datum stream param t type of the input datum stream param k type of key public static t k void write key by datum stream t datum stream string topic property kafka property key selector t k key selector stream execution environment env datum stream get execution environment type serializer t type serializer datum stream get type create serializer env get config write datum to kafka flink kafka shuffle producer t k kafka producer new flink kafka shuffle producer topic type serializer kafka property env clean key selector flink kafka producer semantic exactly once flink kafka producer default kafka producer pool size make sure the sink parallelism be set to producer parallelism precondition check argument kafka property get property producer parallelism null missing producer parallelism for kafka shuffle int producer parallelism property util get int kafka property producer parallelism integer min value add kafka shuffle datum stream kafka producer producer parallelism the write side of link flink kafka shuffle persistent key by p this function contain a link flink kafka shuffle producer to shuffle and persist datum in kafka link flink kafka shuffle producer use the same key group assignment function link key group range assignment assign key to parallel operator to decide which partition a key go p hence each producer task can potentially write to each kafka partition base on the key here the number of partition equal to the key group size in the case of use link time characteristic event time each producer task broadcast each watermark to all of the kafka partition to make sure watermark information be propagate properly p attention make sure kafka property include link flink kafka shuffle producer parallelism and link flink kafka shuffle partition number explicitly link flink kafka shuffle producer parallelism be the parallelism of the producer link flink kafka shuffle partition number be the number of partition they be not necessarily the same and allow to be set independently see flink kafka shuffle persistent key by see flink kafka shuffle read key by param datum stream datum stream to be shuffle param topic kafka topic write to param kafka property kafka property for kafka producer param field key position from the input datum stream param t type of the input datum stream public static t void write key by datum stream t datum stream string topic property kafka property int field write key by datum stream topic kafka property key selector datum stream field the read side of link flink kafka shuffle persistent key by p each consumer task should read kafka partition equal to the key group index it be assign the number of kafka partition be the maximum parallelism of the consumer this version only support number of partition consumer parallelism in the case of use link time characteristic event time a consumer task be responsible to emit watermark watermark be read from the correspond kafka partition notice that a consumer task only start to emit a watermark after receive at least one watermark from each producer task to make sure watermark be monotonically increase hence a consumer task need to know producer parallelism as well p attention make sure kafka property include link flink kafka shuffle producer parallelism and link flink kafka shuffle partition number explicitly link flink kafka shuffle producer parallelism be the parallelism of the producer link flink kafka shuffle partition number be the number of partition they be not necessarily the same and allow to be set independently see flink kafka shuffle persistent key by see flink kafka shuffle write key by param topic the topic of kafka where datum be persist param env execution environment read key by s environment can be different from write key by s param type information type information of the datum persist in kafka param kafka property kafka property for kafka consumer param key selector key selector to retrieve key param t schema type param k key type return key datum stream public static t k keyed stream t k read key by string topic stream execution environment env type information t type information property kafka property key selector t k key selector type serializer t type serializer type information create serializer env get config type information serialization schema t schema new type information serialization schema type information type serializer source function t kafka consumer new flink kafka shuffle consumer topic schema type serializer kafka property todo consider situation where number of partition consumer parallelism precondition check argument kafka property get property partition number null missing partition number for kafka shuffle int number of partition property util get int kafka property partition number integer min value datum stream t output datum stream env add source kafka consumer set parallelism number of partition return datum stream util reinterpret as keyed stream output datum stream key selector add a link stream kafka shuffle sink to link datum stream p link stream kafka shuffle sink be associate a link flink kafka shuffle producer param input stream input datum stream connect to the shuffle param kafka shuffle producer kafka shuffle sink function that can handle both record and watermark param producer parallelism the number of task write to the kafka shuffle private static t k void add kafka shuffle datum stream t input stream flink kafka shuffle producer t k kafka shuffle producer int producer parallelism read the output type of the input transform to coax out error about miss type info input stream get transformation get output type stream kafka shuffle sink t shuffle sink operator new stream kafka shuffle sink kafka shuffle producer sink transformation t transformation new sink transformation input stream get transformation kafka shuffle shuffle sink operator input stream get execution environment get parallelism input stream get execution environment add operator transformation transformation set parallelism producer parallelism a better place to put this function be datum stream but put it here for now to avoid change datum stream private static t key selector t tuple key selector datum stream t source int field key selector t tuple key selector if source get type instanceof basic array type info source get type instanceof primitive array type info key selector key selector util get selector for array field source get type else key t key new key expression key field source get type key selector key selector util get selector for key key source get type source get execution environment get config return key selector 
datum stream util experimental public final class datum stream util return a iterator to iterate over the element of the datum stream return the iterator public static out iterator out collect datum stream out stream type serializer out serializer stream get type create serializer stream get execution environment get config string accumulator name datum stream collect uuid random u u i d to string collect sink operator factory out factory new collect sink operator factory serializer accumulator name collect sink operator out operator collect sink operator out factory get operator collect result iterator out iterator new collect result iterator operator get operator id future serializer accumulator name collect stream sink out sink new collect stream sink stream factory sink name datum stream collect sink stream execution environment env stream get execution environment env add operator sink get transformation try job client job client env execute async datum stream collect iterator set job client job client catch exception e throw new runtime exception fail to execute datum stream e return iterator reinterpret the give link datum stream as a link key stream which extract key with the give link key selector p important for every partition of the base stream the key of event in the base stream must be partition exactly in the same way as if it be create through a link data stream key by key selector param stream the datum stream to reinterpret for every partition this stream must be partition exactly in the same way as if it be create through a link data stream key by key selector param key selector function that define how key be extract from the datum stream param t type of event in the datum stream param k type of the extract key return the reinterpretation of the link data stream as a link key stream public static t k keyed stream t k reinterpret as keyed stream datum stream t stream key selector t k key selector return reinterpret as keyed stream stream key selector type extractor get key selector type key selector stream get type reinterpret the give link datum stream as a link key stream which extract key with the give link key selector p important for every partition of the base stream the key of event in the base stream must be partition exactly in the same way as if it be create through a link data stream key by key selector param stream the datum stream to reinterpret for every partition this stream must be partition exactly in the same way as if it be create through a link data stream key by key selector param key selector function that define how key be extract from the datum stream param type info explicit type information about the key type param t type of event in the datum stream param k type of the extract key return the reinterpretation of the link data stream as a link key stream public static t k keyed stream t k reinterpret as keyed stream datum stream t stream key selector t k key selector type information k type info partition transformation t partition transformation new partition transformation stream get transformation new forward partitioner return new keyed stream stream partition transformation key selector type info private constructor to prevent instantiation private datum stream util 
multiple connected stream experimental public class multiple connected stream protect final stream execution environment environment public multiple connected stream stream execution environment env this environment require non null env public stream execution environment get execution environment return environment public out single output stream operator out transform abstract multiple input transformation out transform return new single output stream operator environment transform 
stream execution environment experimental public out datum stream source out from source source out source watermark strategy out timestamp and watermark string source name return from source source timestamp and watermark source name null 
stream execution environment experimental public out datum stream source out from source source out source watermark strategy out timestamp and watermark string source name type information out type info final type information out resolve type info get type info source source name source class type info return new datum stream source this check not null source source check not null timestamp and watermark timestamp and watermark check not null resolve type info check not null source name 
datum generator experimental public interface datum generator t extend serializable iterator t open and initialize state for link datum generator see link checkpoint function initialize state param name the state of link datum generator should relate to this name make sure the name of state be different void open string name function initialization context context runtime context runtime context throw exception snapshot state for link datum generator see link checkpoint function snapshot state default void snapshot state function snapshot context context throw exception 
datum generator source experimental public class datum generator source t extend rich parallel source function t implement checkpoint function private static final long serial version u i d 1 l private final datum generator t generator private final long row per second transient volatile boolean be run create a source that emit record by link datum generator without control emit rate param generator data generator public datum generator source datum generator t generator this generator long max value create a source that emit record by link data generator param generator datum generator param row per second control the emit rate public datum generator source datum generator t generator long row per second this generator generator this row per second row per second override public void initialize state function initialization context context throw exception this generator open datum generator context get runtime context this be run true override public void snapshot state function snapshot context context throw exception this generator snapshot state context override public void run source context t ctx throw exception double task row per second double row per second get runtime context get number of parallel subtask long next read time system current time millis while be run for int i i task row per second i if be run generator have next synchronize ctx get checkpoint lock ctx collect this generator next else return next read time long to wait ms next read time system current time millis while to wait ms thread sleep to wait ms to wait ms next read time system current time millis override public void cancel be run false 
random generator experimental public abstract class random generator t implement datum generator t protect transient random datum generator random override public void open string name function initialization context context runtime context runtime context throw exception this random new random datum generator override public boolean have next return true public static random generator long long generator long min long max return new random generator long override public long next return random next long min max public static random generator integer int generator int min int max return new random generator integer override public integer next return random next int min max public static random generator short short generator short min short max return new random generator short override public short next return short random next int min max public static random generator byte byte generator byte min byte max return new random generator byte override public byte next return byte random next int min max public static random generator float float generator float min float max return new random generator float override public float next return float random next uniform min max public static random generator double double generator double min double max return new random generator double override public double next return random next uniform min max public static random generator string string generator int len return new random generator string override public string next return random next hex string len public static random generator boolean boolean generator return new random generator boolean override public boolean next return random next int 
sequence generator experimental public abstract class sequence generator t implement datum generator t private final long start private final long end private transient list state long checkpoint state protect transient deque long value to emit create a data generator that emit all number from the give interval exactly once param start start of the range of number to emit param end end of the range of number to emit public sequence generator long start long end this start start this end end override public void open string name function initialization context context runtime context runtime context throw exception precondition check state this checkpoint state null the get class get simple name have already be initialize this checkpoint state context get operator state store get list state new list state descriptor name sequence state long serializer instance this value to emit new array deque if context be restore upon restore for long v this checkpoint state get this value to emit add v else the first time the job be execute final int step size runtime context get number of parallel subtask final int task idx runtime context get index of this subtask final long congruence start task idx long total no of element math abs end start final int base size safe divide total no of element step size final int to collect total no of element step size task idx base size base size for long collect collect to collect collect this value to emit add collect step size congruence override public void snapshot state function snapshot context context throw exception precondition check state this checkpoint state null the get class get simple name state have not be properly initialize this checkpoint state clear for long v this value to emit this checkpoint state add v override public boolean have next return this value to emit be empty private static int safe divide long leave long right precondition check argument right precondition check argument leave precondition check argument left integer max value right return int leave right public static sequence generator long long generator long start long end return new sequence generator long start end override public long next return value to emit poll public static sequence generator integer int generator int start int end return new sequence generator integer start end override public integer next return value to emit poll int value public static sequence generator short short generator short start short end return new sequence generator short start end override public short next return value to emit poll short value public static sequence generator byte byte generator byte start byte end return new sequence generator byte start end override public byte next return value to emit poll byte value public static sequence generator float float generator short start short end return new sequence generator float start end override public float next return value to emit poll float value public static sequence generator double double generator int start int end return new sequence generator double start end override public double next return value to emit poll double value public static sequence generator string string generator long start long end return new sequence generator string start end override public string next return value to emit poll to string 
abstract input experimental public abstract class abstract input in out implement input in code key selector for extract a key from a element be process this be use to scope key state to a key this be null if the operator be not a keyed operator p this be for element from the first input nullable protect final key selector state key selector protect final abstract stream operator v2 out owner protect final int input id protect final output stream record out output public abstract input abstract stream operator v2 out owner int input id check argument input id input be index from this owner owner this input id input id this state key selector owner config get state partitioner input id owner get user code classloader this output owner output override public void process watermark watermark mark throw exception owner report watermark mark input id override public void process latency marker latency marker latency marker throw exception owner report or forward latency marker latency marker override public void set key context element stream record record throw exception owner internal set key context element record state key selector 
abstract stream operator factory experimental public abstract class abstract stream operator factory out implement stream operator factory out processing time service aware protect chain strategy chain strategy chain strategy always protect transient processing time service processing time service override public void set chain strategy chain strategy strategy this chain strategy strategy override public chain strategy get chain strategy return chain strategy override public void set processing time service processing time service processing time service this processing time service processing time service 
abstract stream operator v2 experimental public abstract class abstract stream operator v2 out implement stream operator out checkpointed stream operator the logger use by the operator class and its subclass protect static final logger log logger factory get logger abstract stream operator v2 class protect final stream config config protect final output stream record out output private final streaming runtime context runtime context private final execution config execution config private final class loader user code class loader private final closeable registry cancelable private final long input watermark metric group for the operator protect final operator metric group metric protect final latency stats latency stats protect final processing time service processing time service private stream operator state handler state handler private internal time service manager time service manager we keep track of watermark from both input the combine input be the minimum once the minimum advance we emit a new watermark for downstream operator private long combine watermark long min value public abstract stream operator v2 stream operator parameter out parameter int number of input input watermark new long number of input array fill input watermark long min value final environment environment parameter get contain task get environment config parameter get stream config count output out count output operator metric group operator metric group try operator metric group environment get metric group get or add operator config get operator i d config get operator name count output new counting output parameter get output operator metric group get i o metric group get num record out counter if config be chain start operator metric group get i o metric group reuse input metric for task if config be chain end operator metric group get i o metric group reuse output metric for task catch exception e log warn a error occur while instantiate task metric e count output null operator metric group null if count output null operator metric group null metric unregistered metric group create unregistered operator metric group output parameter get output else metric operator metric group output count output latency stats create latency stats environment get task manager info get configuration parameter get contain task get index in subtask group processing time service precondition check not null parameter get process time service execution config parameter get contain task get execution config user code class loader parameter get contain task get user code class loader cancelable parameter get contain task get cancelable runtime context new streaming runtime context environment environment get accumulator registry get user map operator metric group get operator i d processing time service null environment get external resource info provider private latency stats create latency stats configuration task manager config int index in subtask group try int history size task manager config get integer metric option latency history size if history size log warn have be set to a value equal or below use default metric option latency history size history size history size metric option latency history size default value final string configure granularity task manager config get string metric option latency source granularity latency stats granularity granularity try granularity latency stats granularity value of configure granularity to upper case locale root catch illegal argument exception iae granularity latency stats granularity operator log warn configure value option for be invalid default to configure granularity metric option latency source granularity key granularity task manager job metric group job metric group this metric parent parent return new latency stats job metric group add group latency history size index in subtask group get operator i d granularity catch exception e log warn a error occur while instantiate latency metric e return new latency stats unregistered metric group create unregistered task manager job metric group add group latency new operator i d latency stats granularity single override public metric group get metric group return metric override public final void initialize state stream task state initializer stream task state manager throw exception final type serializer key serializer config get state key serializer get user code classloader final stream operator state context context stream task state manager stream operator state context get operator i would get class get simple name get processing time service this key serializer cancelable metric state handler new stream operator state handler context get execution config cancelable time service manager context internal timer service manager state handler initialize operator state this this method be call immediately before any element be process it should contain the operator s initialization logic e g state initialization p the default implementation do nothing throw exception a exception in this method cause the operator to fail override public void open throw exception this method be call after all record have be add to the operator via the method link one input stream operator process element stream record or link two input stream operator process element1 stream record and link two input stream operator process element2 stream record p the method be expect to flush all remain buffer datum exception during this flush of buffer should be propagate in order to cause the operation to be recognize asa fail because the last datum item be not process properly throw exception a exception in this method cause the operator to fail override public void close throw exception this method be call at the very end of the operator s life both in the case of a successful completion of the operation and in the case of a failure and cancel p this method be expect to make a thorough effort to release all resource that the operator have acquire override public void dispose throw exception if state handler null state handler dispose override public void prepare snapshot pre barrier long checkpoint id throw exception the default implementation do nothing and accept the checkpoint this be purely for subclass to override override public final operator snapshot future snapshot state long checkpoint id long timestamp checkpoint option checkpoint option checkpoint stream factory factory throw exception return state handler snapshot state this optional of nullable time service manager get operator name checkpoint id timestamp checkpoint option factory stream operator with state which want to participate in a snapshot need to override this hook method param context context that provide information and mean require for take a snapshot override public void snapshot state state snapshot context context throw exception stream operator with state which can be restore need to override this hook method param context context that allow to register different state override public void initialize state state initialization context context throw exception override public void notify checkpoint complete long checkpoint id throw exception state handler notify checkpoint complete checkpoint id override public void notify checkpoint aborted long checkpoint id throw exception state handler notify checkpoint aborted checkpoint id property and service get the execution config define on the execution environment of the job to which this operator belong return the job s execution config public execution config get execution config return execution config public stream config get operator config return config public class loader get user code classloader return user code class loader return the operator name if the runtime context have be set then the task name with subtask index be return otherwise the simple class name be return return if runtime context be set then return task name with subtask index otherwise return simple class name protect string get operator name if runtime context null return runtime context get task name with subtask else return get class get simple name return a context that allow the operator to query information about the execution and also to interact with system such as broadcast variable and manage state this also allow to register timer public streaming runtime context get runtime context return runtime context suppress warning unchecked visible for test public k key state backend k get key state backend return key state backend k state handler get key state backend visible for test public operator state backend get operator state backend return state handler get operator state backend return the link processing time service responsible for get the current processing time and register timer visible for test public processing time service get processing time service return processing time service create a partition state handle use the state backend configure for this task throw illegal state exception throw if the key value state be already initialize throw exception throw if the state backend can not create the key value state protect s extend state s get partition state state descriptor s state descriptor throw exception return get partition state void namespace instance void namespace serializer instance state descriptor protect n s extend state t s get or create key state type serializer n namespace serializer state descriptor s t state descriptor throw exception return state handler get or create key state namespace serializer state descriptor create a partition state handle use the state backend configure for this task throw illegal state exception throw if the key value state be already initialize throw exception throw if the state backend can not create the key value state protect s extend state n s get partition state n namespace type serializer n namespace serializer state descriptor s state descriptor throw exception return state handler get partition state namespace namespace serializer state descriptor protect t void internal set key context element stream record t record key selector t selector throw exception if selector null object key selector get key record get value set current key key suppress warning unchecked rawtype public void set current key object key state handler set current key key suppress warning unchecked rawtype public object get current key return state handler get current key public optional key state store get key state store if state handler null return optional empty return state handler get key state store protect void report or forward latency marker latency marker marker all operator be track latency this latency stats report latency marker everything except sink forward latency marker this output emit latency marker marker watermark handle return a link internal timer service that can be use to query current processing time and event time and to set timer a operator can have several timer service where each have its own namespace serializer timer service be differentiate by the string key that be give when request they if you call this method with the same key multiple time you will get the same timer service instance in subsequent request p timer be always scop to a key the currently active key of a keyed stream operation when a timer fire this key will also be set as the currently active key p each timer have attach metadata the namespace different timer service can have a different namespace type if you don t need namespace differentiation you can use link void namespace serializer as the namespace serializer param name the name of the request timer service if no service exist under the give name a new one will be create and return param namespace serializer code type serializer for the timer namespace param triggerable the link triggerable that should be invoke when timer fire param n the type of the timer namespace visible for test public k n internal timer service n get internal timer service string name type serializer n namespace serializer triggerable k n triggerable if time service manager null throw new runtime exception the timer service have not be initialize internal time service manager k key time service handler internal time service manager k time service manager return key time service handler get internal timer service name namespace serializer triggerable state handler get key state backend public void process watermark watermark mark throw exception if time service manager null time service manager advance watermark mark output emit watermark mark protect void report watermark watermark mark int input id throw exception input watermark input id mark get timestamp long new min mark get timestamp for long input watermark input watermark new min math min input watermark new min if new min combine watermark combine watermark new min process watermark new watermark combine watermark override public operator i would get operator i d return config get operator i d visible for test public int num processing time timer return time service manager null time service manager num processing time timer visible for test public int num event time timer return time service manager null time service manager num event time timer override public void set key context element1 stream record record throw exception throw new illegal state exception this method should never be call use input class instead override public void set key context element2 stream record record throw exception throw new illegal state exception this method should never be call use input class instead protect optional internal time service manager get time service manager return optional of nullable time service manager 
stream operator factory experimental public interface stream operator factory out extend serializable create the operator set access to the context and the output t extend stream operator out t create stream operator stream operator parameter out parameter set the chain strategy for operator factory void set chain strategy chain strategy strategy get the chain strategy of operator factory chain strategy get chain strategy be this factory for link stream source default boolean be stream source return false if the stream operator need access to the output type information at link stream graph generation this can be useful for case where the output type be specify by the return method and thus after the stream operator have be create default boolean be output type configurable return false be call by the link stream graph add operator method when the link stream graph be generate the method be call with the output link type information which be also use for the link stream task output serializer param type output type information of the link stream task param execution config execution configuration default void set output type type information out type execution config execution config if the stream operator need to be configure with the datum type they will operate on default boolean be input type configurable return false be call by the link stream graph add operator method when the link stream graph be generate param type the datum type of the input param execution config the execution config for this parallel execution default void set input type type information type execution config execution config return the runtime class of the stream operator class extend stream operator get stream operator class class loader class loader 
stream operator parameter experimental public class stream operator parameter out private final stream task contain task private final stream config config private final output stream record out output private final supplier processing time service processing time service factory private final operator event dispatcher operator event dispatcher the processing time service lazily create but cache so that we don t create more than one nullable private processing time service processing time service public stream operator parameter stream task contain task stream config config output stream record out output supplier processing time service processing time service factory operator event dispatcher operator event dispatcher this contain task contain task this config config this output output this processing time service factory processing time service factory this operator event dispatcher operator event dispatcher public stream task get contain task return contain task public stream config get stream config return config public output stream record out get output return output public processing time service get processing time service if processing time service null processing time service processing time service factory get return processing time service public operator event dispatcher get operator event dispatcher return operator event dispatcher 
yield operator factory experimental public interface yield operator factory out extend stream operator factory out void set mailbox executor mailbox executor mailbox executor 
collect sink experimental public class collect sink in extend rich sink function in private static final long serial version u i d 1 l private final inet address host ip private final int port private final type serializer in serializer private transient socket client private transient output stream output stream private transient datum output view stream wrapper stream writer create a collect sink that will send the datum to the specify host param host ip ip address of the socket server param port port of the socket server param serializer a serializer for the datum public collect sink inet address host ip int port type serializer in serializer this host ip host ip this port port this serializer serializer override public void invoke in value context context throw exception try serializer serialize value stream writer catch exception e throw new i o exception error send datum back to client host ip to string port e initialize the connection with the socket in the server param parameter configuration override public void open configuration parameter throw exception try client new socket host ip port output stream client get output stream stream writer new datum output view stream wrapper output stream catch i o exception e throw new i o exception can not connect to the client to send back the stream e close the connection with the socket server override public void close throw exception try if output stream null output stream flush output stream close first regular attempt to cleanly close fail that will escalate if client null client close catch exception e throw new i o exception error while close connection that stream datum back to client at host ip to string port e finally if we fail prior to close the client close it if client null try client close catch throwable t best effort to close we do not care about a exception here any more 
socket stream iterator experimental public class socket stream iterator t implement iterator t server socket to listen at private final server socket socket serializer to deserialize stream private final type serializer t serializer set by the same thread that read it private datum input view stream wrapper in stream next element handover from have next to next private t next the socket for the specific stream private socket connect socket async error for example by the executor of the program that produce the stream private volatile throwable error create a iterator that return the datum from a socket stream with automatic port and bind address param serializer serializer use for deserialize incoming record throw i o exception throw if socket can not be open public socket stream iterator type serializer t serializer throw i o exception this null serializer create a iterator that return the datum from a socket stream with custom port and bind address param port port for the socket connection mean automatic port selection param address address for the socket connection param serializer serializer use for deserialize incoming record throw i o exception throw if socket can not be open public socket stream iterator int port inet address address type serializer t serializer throw i o exception this serializer serializer try socket new server socket port address catch i o exception e throw new runtime exception could not open socket to receive back stream result property return the port on which the iterator be get the datum use internally return the port public int get port return socket get local port public inet address get bind address return socket get inet address public void close if connect socket null try connect socket close catch throwable ignore try socket close catch throwable ignore iterator semantics return true if the datum stream have more element note block if there will be more element but they be not available yet return true if the datum stream have more element override public boolean have next if next null try next read next from stream catch exception e throw new runtime exception fail to receive next element e get message e return next null return the next element of the datum stream block if it be not available yet return the element throw no such element exception if the stream have already end override public t next if have next t current next next null return current else throw new no such element exception override public void remove throw new unsupported operation exception private t read next from stream throw exception try if in stream null connected socket socket accept in stream new datum input view stream wrapper connect socket get input stream return serializer deserialize in stream catch e o f exception e try connect socket close catch throwable ignore try socket close catch throwable ignore return null catch exception e if error null throw e else throw the root cause error throw new exception receive stream fail error get message error error public void notify of error throwable error if error null this error null this error error this should wake up any block call try connect socket close catch throwable ignore try socket close catch throwable ignore 
table config experimental public void add job parameter string key string value map string string param get configuration get optional pipeline option global job parameter map hash map new or else get hash map new param put key value get configuration set pipeline option global job parameter param 
table environment experimental void create temporary system function string name class extend user define function function class 
table environment experimental void create temporary system function string name user define function function instance 
table environment experimental boolean drop temporary system function string name 
table environment experimental void create function string path class extend user define function function class 
table environment experimental void create function string path class extend user define function function class boolean ignore if exist 
table environment experimental boolean drop function string path 
table environment experimental void create temporary function string path class extend user define function function class 
table environment experimental void create temporary function string path user define function function instance 
table environment experimental boolean drop temporary function string path 
output format table sink experimental public abstract class output format table sink t implement stream table sink t return a link output format for write the datum of the table public abstract output format t get output format override public final datum stream sink t consume datum stream datum stream t datum stream return datum stream write use output format get output format set parallelism datum stream get parallelism 
input format table source experimental public abstract class input format table source t implement stream table source t return a link input format for read the datum of the table public abstract input format t get input format always return true which indicate this be a bound source override public final boolean be bound return true suppress warning unchecked override public final datum stream t get datum stream stream execution environment exec env type information t type info type information t from datum type to legacy info get produce datum type return exec env create input get input format type info 
lookup table source experimental public interface lookup table source extend dynamic table source return a provider of runtime implementation for read the datum p there exist different interface for runtime implementation which be why link lookup runtime provider serve as the base interface p independent of the provider interface a source implementation can work on either arbitrary object or internal datum structure see link org apache flink table datum for more information p the give link lookup context offer utility by the planner for create runtime implementation with minimal dependency to internal datum structure see table function provider see async table function provider lookup runtime provider get lookup runtime provider lookup context context helper interface context for create runtime implementation via a link lookup runtime provider p it offer utility by the planner for create runtime implementation with minimal dependency to internal datum structure p method should be call in link get lookup runtime provider lookup context return instance that be link serializable can be directly pass into the runtime implementation class interface lookup context extend dynamic table source context return a array of key index path that should be use during the lookup the index be base and support composite key within possibly nest structure p for example give a table with datum type code row i int s string r row i2 int s2 string this method would return code when code i and code s2 be use for perform a lookup return array of key index path int get key provide actual runtime implementation for read the datum p there exist different interface for runtime implementation which be why link lookup runtime provider serve as the base interface see table function provider see async table function provider interface lookup runtime provider marker interface 
async table function experimental public abstract class async table function t extend user define function return the result type of the evaluation method with a give signature p this method need to be override in case flink s type extraction facility be not sufficient to extract the link type information base on the return type of the evaluation method flink s type extraction facility can handle basic type or simple p o j os but might be wrong for more complex custom or composite type return link type information of result type or code null code if flink should determine the type public type information t get result type return null override public final function kind get kind return function kind async table override public type inference get type inference datum type factory type factory throw new table exception async table function be not update to the new type system yet 
overwritable table sink experimental public interface overwritable table sink configure whether the insert should overwrite exist datum or not void set overwrite boolean overwrite 
partitionable table sink experimental public interface partitionable table sink set the static partition into the link table sink the static partition may be partial of all partition column see the class javadoc for more detail p the static partition be represent as a code map string string which map from partition field name to partition value the partition value be all encode as string i e encode use string value of for example if we have a static partition code f0 f1 foo f2 bar f0 be a integer type f1 and f2 be string type they will all be encode as string foo bar and can be decode to original literal base on the field type param partition user specify static partition void set static partition map string string partition if return true sink can trust all record will definitely be group by partition field before consume by the link table sink i e the sink will receive all element of one partition and then all element of another partition element of different partition will not be mix for some sink this can be use to reduce number of the partition writer to improve write performance p this method be use to configure the behavior of input whether to be group by partition if true at the same time the sink should also configure itself i e set a internal field that change the writing behavior write one partition at a time param support grouping whether the execution mode support grouping e g grouping usually use sort to implement be only support in batch mode not support in streaming mode return whether datum need to be group by partition before consume by the sink default be false if code support grouping be false it should never return true require grouping otherwise it will fail default boolean configure partition grouping boolean support grouping return false 
limitable table source experimental public interface limitable table source t return the flag to indicate whether limit push down have be try must return true on the return instance of link apply limit long boolean be limit push down check and push down the limit to the table source param limit the value which limit the number of record return a new clone instance of link table source table source t apply limit long limit 
lookupable table source experimental public interface lookupable table source t extend table source t get the link table function which support lookup one key at a time param lookup key the choose field name as lookup key it be in the define order table function t get lookup function string lookup key get the link async table function which support async lookup one key at a time param lookup key the choose field name as lookup key it be in the define order async table function t get async lookup function string lookup key return true if async lookup be enable p the lookup function return by link get async lookup function string will be use if return true otherwise the lookup function return by link get lookup function string will be use boolean be async enable 
partitionable table source experimental public interface partitionable table source return all the partition of this link partitionable table source list map string string get partition apply the remain partition to the table source the code remain partition be the remain partition of link get partition after partition pruning apply p after try to apply partition pruning we should return a new link table source instance which hold all prune partition param remain partition remain partition after partition pruning apply return a new clone instance of link table source hold all prune partition table source apply partition pruning list map string string remain partition 
partition commit policy experimental public interface partition commit policy string metastore metastore string success file success file string custom custom commit a partition void commit context context throw exception context of policy include table information and partition information interface context catalog name of this table string catalog name database name of this table string database name table name string table name table partition key list string partition key value of this partition list string partition value path of this partition path partition path partition spec in the form of a map from partition key to value default link hash map string string partition spec link hash map string string re new link hash map for int i i partition key size i re put partition key get i partition value get i return re create a policy chain from config static list partition commit policy create policy chain class loader cl string policy kind string custom class string success file name supplier file system f supplier if policy kind null return collection empty list string policy string policy kind split return array stream policy string map name switch name to lower case case metastore return new metastore commit policy case success file return new success file commit policy success file name f supplier get case custom try return partition commit policy cl load class custom class new instance catch class not find exception illegal access exception instantiation exception e throw new runtime exception can not new instance for custom class from custom class e default throw new unsupported operation exception unsupported policy name collect collector to list validate commit policy static void validate policy chain boolean be empty metastore string policy kind if policy kind null string policy string policy kind split for string policy policy string if be empty metastore metastore equal ignore case policy throw new validation exception can not configure a metastore partition commit policy for a file system table you can only configure metastore partition commit policy for a hive table 
partition time extractor experimental public interface partition time extractor extend serializable string default default string custom custom extract time from partition key and value local date time extract list string partition key list string partition value static partition time extractor create class loader user class loader string extractor kind string extractor class string extractor pattern switch extractor kind case default return new default part time extractor extractor pattern case custom try return partition time extractor user class loader load class extractor class new instance catch class not find exception illegal access exception instantiation exception e throw new runtime exception can not new instance for custom class from extractor class e default throw new unsupported operation exception unsupported extractor kind extractor kind 
